{
    "cells": [
        {
            "language": "typescript",
            "source": [
                "// 加载 .env 中的所有环境变量\nimport 'dotenv/config';"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "text/plain",
                            "value": [
                                "{}"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "// 直接使用 OpenAI Model 完成一次提问\nimport { OpenAI } from \"langchain/llms/openai\";\n\nconst model = new OpenAI({\n  modelName: 'gpt-3.5-turbo',\n  temperature: 0.5,\n});\n\nawait model.call('怎么评价人工智能');"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "(node:791) Warning: Setting the NODE_TLS_REJECT_UNAUTHORIZED environment variable to '0' makes TLS connections and HTTPS requests insecure by disabling certificate verification.",
                                "(Use `node --trace-warnings ...` to show where the warning was created)",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "text/plain",
                            "value": [
                                "\u001b[32m'人工智能是一种能够模拟人类智能的技术，它可以通过学习、推理、感知和交流等方式来实现各种任务。以下是对人工智能的评价：\\n'\u001b[39m +",
                                "  \u001b[32m'\\n'\u001b[39m +",
                                "  \u001b[32m'1. 创新性：人工智能的出现为许多领域带来了全新的解决方案和创新思维。它可以处理大量的数据并从中提取有价值的信息，从而帮助人们做出更明智的决策。\\n'\u001b[39m +",
                                "  \u001b[32m'\\n'\u001b[39m +",
                                "  \u001b[32m'2. 高效性：人工智能可以在短时间内处理大量的信息，而且能够快速学习和适应新的环境。这使得它在许多领域中能够取代人力劳动，提高工作效率。\\n'\u001b[39m +",
                                "  \u001b[32m'\\n'\u001b[39m +",
                                "  \u001b[32m'3. 精确性：人工智能在执行任务时通常能够准确无误地完成，且不会受到情绪、疲劳或其他人类因素的影响。这使得它在某些需要高度精确性的领域中具有巨大的潜力，如医疗诊断、金融分析等。\\n'\u001b[39m +",
                                "  \u001b[32m'\\n'\u001b[39m +",
                                "  \u001b[32m'4. 自主性：一些人工智能系统具备自主学习和决策的能力，可以通过不断的反馈和调整来提高自身的性能。这使得它们能够在没有人类干预的情况下进行自主决策，并逐渐提高自身的智能水平。\\n'\u001b[39m +",
                                "  \u001b[32m'\\n'\u001b[39m +",
                                "  \u001b[32m'5. 潜在风险：尽管人工智能有许多优点，但也存在一些潜在的风险和挑战。例如，人工智能可能会取代人类的工作岗位，导致失业问题；同时，人工智能也可能因为缺乏道德判断力而产生不符合伦理标准的行为。\\n'\u001b[39m +",
                                "  \u001b[32m'\\n'\u001b[39m +",
                                "  \u001b[32m'综上所述，人工智能是一项具有巨大潜力和创新性的技术，它在许多领域中都能够发挥重要作用。然而，我们也需要审慎对待人工智能的发展，确保其在符合伦理和社会价值的前提下发挥正面影响。'\u001b[39m"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "// 使用 Agent 通过 Google 搜索并返回答案\nimport { OpenAI } from 'langchain/llms/openai';\nimport { OpenAIEmbeddings } from 'langchain/embeddings/openai';\nimport { initializeAgentExecutorWithOptions } from 'langchain/agents';\nimport { SerpAPI } from 'langchain/tools';\nimport { Calculator } from 'langchain/tools/calculator';\nimport { WebBrowser } from 'langchain/tools/webbrowser';\n\n// 加载 OpenAI 模型\nconst model = new OpenAI({ temperature: 0 });\nconst embeddings = new OpenAIEmbeddings();\n\n// 加载 SerpAPI 工具\nconst tools = [\n  new SerpAPI(process.env.SERPAPI_API_KEY, {\n    location: 'Austin,Texas,United States',\n    hl: 'en',\n    gl: 'us',\n  }),\n  new Calculator(),\n  new WebBrowser({ model, embeddings }),\n];\n\n// 初始化 Agent，并加载工具\nconst executor = await initializeAgentExecutorWithOptions(tools, model, {\n  agentType: 'zero-shot-react-description',\n  verbose: true,\n});\nconsole.log('Loaded agent.');\n\nconst input = `What is the word of the day on merriam webster. What is the top result on google for that word`;\nconsole.log(`Executing with input \"${input}\"...`);\n\n// 执行 Agent\nawait executor.call({ input });"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "Loaded agent.",
                                "Executing with input \"What is the word of the day on merriam webster. What is the top result on google for that word\"...",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:agent_executor > 2:chain:llm_chain > \u001b[1m3:llm:openai\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"Answer the following questions as best you can. You have access to the following tools:\\n\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\nweb-browser: useful for when you need to find something on or summarize a webpage. input should be a comma separated list of \\\"ONE valid http URL including protocol\\\",\\\"what you want to find on the page or empty string for a summary\\\".\\n\\nUse the following format in your response:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [search,calculator,web-browser]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: What is the word of the day on merriam webster. What is the top result on google for that word\\nThought:\"",
                                "  ]",
                                "}",
                                "\u001b[32m[tool/start]\u001b[39m [\u001b[90m1:chain:agent_executor > \u001b[1m4:tool:web-browser\u001b[22m\u001b[39m] Entering Tool run with input: \"https://www.merriam-webster.com/word-of-the-day\",\"",
                                "/p1?refc=INLINE_WOD_MWU) Words at Play [ 12 political putdowns kakistocracy](https://www.merriam-webster.com/words-at-play/political-putdowns) 12 Political Putdowns For When 'Lowdown Crook' Isn't Specific Enough [ image2135812303](https://www.merriam-webster.com/words-at-play/letters-that-are-not-seen-but-are-heard-in-words#:~:text=This%20is%20quite%20a%20common,this%20type%20of%20alteration%20dissimilation.) Absent Letters That Are Heard Anyway When letters make sounds that aren't associated w... [ image1650711902](https://www.merriam-webster.com/words-at-play/that-sucks-vocabulary-replacements) Better Ways to Say \\\"This Sucks\\\" Go on...make your English teacher proud. [ merriam webster time\\n\\nI need a summary from the above text, also provide up to 5 markdown links from within that would be of interest (always including URL and text). Links should be provided, if present, in markdown syntax as a list under the heading \\\"Relevant Links:\\\".\"",
                                "  ]",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:agent_executor > 6:chain:llm_chain > \u001b[1m7:llm:openai\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"Answer the following questions as best you can. You have access to the following tools:\\n\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\nweb-browser: useful for when you need to find something on or summarize a webpage. input should be a comma separated list of \\\"ONE valid http URL including protocol\\\",\\\"what you want to find on the page or empty string for a summary\\\".\\n\\nUse the following format in your response:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [search,calculator,web-browser]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: What is the word of the day on merriam webster. What is the top result on google for that word\\nThought: I need to find the word of the day on Merriam Webster and then search for it on Google\\nAction: web-browser\\nAction Input: \\\"https://www.merriam-webster.com/word-of-the-day\\\", \\\"\\\"\\nObservation: \\n\\nSummary: Merriam-Webster is a website that provides a variety of services, including a dictionary, thesaurus, word of the day, games and quizzes, and other features. It also provides a login feature for users to save words, view recents, and access their account settings. The word of the day is \\\"laden,\\\" which means heavily loaded with something. The website also provides quizzes and games to help users build their vocabulary. \\n\\nRelevant Links: \\n- [Test Your Vocabulary](https://www.merriam-webster.com/games) \\n- [Thesaurus](https://www.merriam-webster.com/thesaurus) \\n- [Word Finder](https://www.merriam-webster.com/wordfinder) \\n- [Word of the Day](https://www.merriam-webster.com/word-of-the-day) \\n- [Shop](https://shop.merriam-webster.com/?utm_source=mwsite&utm_medium=nav&utm_content=header)\\nThought:\"",
                                "  ]",
                                "}",
                                "\u001b[32m[tool/start]\u001b[39m [\u001b[90m1:chain:agent_executor > \u001b[1m8:tool:search\u001b[22m\u001b[39m] Entering Tool run with input: \"laden\"",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:agent_executor > 9:chain:llm_chain > \u001b[1m10:llm:openai\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"Answer the following questions as best you can. You have access to the following tools:\\n\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\nweb-browser: useful for when you need to find something on or summarize a webpage. input should be a comma separated list of \\\"ONE valid http URL including protocol\\\",\\\"what you want to find on the page or empty string for a summary\\\".\\n\\nUse the following format in your response:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [search,calculator,web-browser]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: What is the word of the day on merriam webster. What is the top result on google for that word\\nThought: I need to find the word of the day on Merriam Webster and then search for it on Google\\nAction: web-browser\\nAction Input: \\\"https://www.merriam-webster.com/word-of-the-day\\\", \\\"\\\"\\nObservation: \\n\\nSummary: Merriam-Webster is a website that provides a variety of services, including a dictionary, thesaurus, word of the day, games and quizzes, and other features. It also provides a login feature for users to save words, view recents, and access their account settings. The word of the day is \\\"laden,\\\" which means heavily loaded with something. The website also provides quizzes and games to help users build their vocabulary. \\n\\nRelevant Links: \\n- [Test Your Vocabulary](https://www.merriam-webster.com/games) \\n- [Thesaurus](https://www.merriam-webster.com/thesaurus) \\n- [Word Finder](https://www.merriam-webster.com/wordfinder) \\n- [Word of the Day](https://www.merriam-webster.com/word-of-the-day) \\n- [Shop](https://shop.merriam-webster.com/?utm_source=mwsite&utm_medium=nav&utm_content=header)\\nThought: Now I need to search for the word of the day on Google\\nAction: search\\nAction Input: \\\"laden\\\"\\nObservation: Osama bin Mohammed bin Awad bin Laden was a Saudi Arabian-born militant and founder of the pan-Islamic militant organization Al-Qaeda. The group is designated as a terrorist group by the United Nations Security Council, the North Atlantic Treaty Organization, the European Union, and various other countries.\\nThought:\"",
                                "  ]",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:agent_executor > \u001b[1m9:chain:llm_chain\u001b[22m\u001b[39m] [4.45s] Exiting Chain run with output: {",
                                "  \"text\": \" I now know the final answer\\nFinal Answer: Osama bin Mohammed bin Awad bin Laden is the top result on Google for the word of the day \\\"laden\\\" on Merriam Webster.\"",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:agent_executor\u001b[22m\u001b[39m] [53.20s] Exiting Chain run with output: {",
                                "  \"output\": \"Osama bin Mohammed bin Awad bin Laden is the top result on Google for the word of the day \\\"laden\\\" on Merriam Webster.\"",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "text/plain",
                            "value": [
                                "{",
                                "  output: \u001b[32m'Osama bin Mohammed bin Awad bin Laden is the top result on Google for the word of the day \"laden\" on Merriam Webster.'\u001b[39m",
                                "}"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "// 使用 Text Loader 对超长文本进行总结和问答\nimport { OpenAI } from 'langchain/llms/openai';\nimport { TextLoader } from 'langchain/document_loaders/fs/text';\nimport { loadSummarizationChain, loadQARefineChain } from 'langchain/chains';\nimport { RecursiveCharacterTextSplitter } from 'langchain/text_splitter';\n\n// 初始化文本分割器\nconst splitter = new RecursiveCharacterTextSplitter({\n  chunkSize: 500,\n  chunkOverlap: 0,\n});\n\n// 导入文本\nconst loader = new TextLoader('data/large_text.txt');\nconst docs = await loader.loadAndSplit(splitter);\nconsole.log('[ # of split documents ] >', docs.length);\n\n// 加载 OpenAI 模型\nconst model = new OpenAI({ maxTokens: 1500 });\n\n// 创建并执行总结链（为了快速演示，只总结前 3 段）\nconst chainSum = loadSummarizationChain(model, {\n  type: 'refine',\n  verbose: true,\n});\nconst summary = await chainSum.call({\n  input_documents: docs.slice(0, 3),\n});\nconsole.log('[ summary ] >', summary)\n\n// 创建并执行问答链（为了快速演示，只查询前 3 段）\nconst chainQA = loadQARefineChain(model);\nconst answer = await chainQA.call({\n  input_documents: docs.slice(0, 3),\n  question: '秦逸是谁？',\n});\nconsole.log('[ answer ] >', answer)"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "[ # of split documents ] > 360",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:refine_documents_chain > \u001b[1m2:chain:llm_chain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"text\": \"声明：本书为爱奇电子书(www.i7wu.cn)的用户上传至其在本站的存储空间，本站只提供TXT全集电子书存储服务以及免费下载服务，以下作品内容之版权与本站无任何关系。\\n---------------------------用户上传之内容开始--------------------------------\\n《地藏心经》\\n作者：铸剑师无名\\n\\n\\n正文\"",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:refine_documents_chain > \u001b[1m4:chain:llm_chain\u001b[22m\u001b[39m] [12.15s] Exiting Chain run with output: {",
                                "  \"text\": \"\\nThis book is uploaded by users to the storage space of i7wu.cn, a website that only provides TXT full set e-book storage and free download services. The copyright of the following works has no relation with the website. The book is called \\\"地藏心经\\\" and is written by 铸剑师无名. It tells the story of the Lu family, who rose to power in the Jiangnan region, through their business in the trading of furs from the northwest. Over the course of a century, the Lu family produced many talented individuals, and eventually controlled the military forces in the regions of Yu and Yu. After a decade, the southern dynasty was nearly powerless and the regions were split into various factions, all under the control of the Lu family.\"",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:refine_documents_chain > \u001b[1m6:chain:llm_chain\u001b[22m\u001b[39m] [14.44s] Exiting Chain run with output: {",
                                "  \"text\": \" \\nThis book is uploaded by users to the storage space of i7wu.cn, a website that only provides TXT full set e-book storage and free download services. The copyright of the following works has no relation with the website. The book is called \\\"地藏心经\\\" and is written by 铸剑师无名. It tells the story of the Lu family, who rose to power in the Jiangnan region, through their business in the trading of furs from the northwest. Over the course of a century, the Lu family produced many talented individuals and eventually controlled the military forces in the regions of Yu and Yu. This caused the southern dynasty to become nearly powerless, leading to the regions being split into various factions, all under the control of the Lu family. The Lu family was able to establish dominance over the other families in the area, including the Deng, Li, Su, He, and Gongsun families in the northwest, the Lu, Xiong, Liu, and Zheng families in the south, and the three provinces in the east. They were even able to secure a boat from the Lu family's car business in Yuzhou, despite their weakened status.\"",
                                "}",
                                "[ summary ] > {",
                                "  output_text: ' \\n' +",
                                "    `This book is uploaded by users to the storage space of i7wu.cn, a website that only provides TXT full set e-book storage and free download services. The copyright of the following works has no relation with the website. The book is called \"地藏心经\" and is written by 铸剑师无名. It tells the story of the Lu family, who rose to power in the Jiangnan region, through their business in the trading of furs from the northwest. Over the course of a century, the Lu family produced many talented individuals and eventually controlled the military forces in the regions of Yu and Yu. This caused the southern dynasty to become nearly powerless, leading to the regions being split into various factions, all under the control of the Lu family. The Lu family was able to establish dominance over the other families in the area, including the Deng, Li, Su, He, and Gongsun families in the northwest, the Lu, Xiong, Liu, and Zheng families in the south, and the three provinces in the east. They were even able to secure a boat from the Lu family's car business in Yuzhou, despite their weakened status.`",
                                "}",
                                "[ answer ] > {",
                                "  output_text: '\\n' +",
                                "    '\\n' +",
                                "    '秦逸是虚构的人物，是《地藏心经》中的主角，由铸剑师无名创作。他是一位苦读诗书的学士，他的家庭来自西北，与渝州陆家无关。但是在渝州，秦家早已家道中落，与陆家比不得，不敢与其争船。'",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "Error in handler ConsoleCallbackHandler, handleChainStart: Error: Parent run 069f9ad0-ca6a-401e-a353-2b87ea07d1e0 not found",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:refine_documents_chain > 2:chain:llm_chain > \u001b[1m3:llm:openai\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"Write a concise summary of the following:\\n\\n\\n\\\"声明：本书为爱奇电子书(www.i7wu.cn)的用户上传至其在本站的存储空间，本站只提供TXT全集电子书存储服务以及免费下载服务，以下作品内容之版权与本站无任何关系。\\n---------------------------用户上传之内容开始--------------------------------\\n《地藏心经》\\n作者：铸剑师无名\\n\\n\\n正文\\\"\\n\\n\\nCONCISE SUMMARY:\"",
                                "  ]",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "Error in handler ConsoleCallbackHandler, handleLLMStart: Error: Parent run db08f40a-827a-4297-afe0-a7bfb8390e51 not found",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:refine_documents_chain > 2:chain:llm_chain > \u001b[1m3:llm:openai\u001b[22m\u001b[39m] [7.11s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \" \\nThis book is uploaded by users to the storage space of i7wu.cn, a website that only provides TXT full set e-book storage and free download services. The copyright of the following works has no relation with the website. The book is called \\\"地藏心经\\\" and is written by 铸剑师无名.\",",
                                "        \"generationInfo\": {",
                                "          \"finishReason\": \"stop\",",
                                "          \"logprobs\": null",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 82,",
                                "      \"promptTokens\": 229,",
                                "      \"totalTokens\": 311",
                                "    }",
                                "  }",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "Error in handler ConsoleCallbackHandler, handleLLMEnd: Error: No LLM run to end.",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:refine_documents_chain > \u001b[1m2:chain:llm_chain\u001b[22m\u001b[39m] [7.11s] Exiting Chain run with output: {",
                                "  \"text\": \" \\nThis book is uploaded by users to the storage space of i7wu.cn, a website that only provides TXT full set e-book storage and free download services. The copyright of the following works has no relation with the website. The book is called \\\"地藏心经\\\" and is written by 铸剑师无名.\"",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "Error in handler ConsoleCallbackHandler, handleChainEnd: Error: No chain run to end.",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:refine_documents_chain > \u001b[1m4:chain:llm_chain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"existing_answer\": \" \\nThis book is uploaded by users to the storage space of i7wu.cn, a website that only provides TXT full set e-book storage and free download services. The copyright of the following works has no relation with the website. The book is called \\\"地藏心经\\\" and is written by 铸剑师无名.\",",
                                "  \"text\": \"第一第十五章 天下势，渡江（一）\\n    “渝州陆家？！”\\n    虽然原本的那个秦逸，每日只知道苦读诗书，从未与商贾们打过交道，但是渝州陆家的名声，他还是知道。\\n    陆家三代为官，官至两江总督，五代经商，百年经营，家私何止千万，直至今朝，俨然已是江南一等士族大户。渝州陆氏以皮货起家，乃是西北之地数得上号的商户，西北之地所产的皮货，有三成经他们之手卖往江南。\\n    若只是如此，陆氏也不过是一头肥硕的羔羊，只待他人宰杀。\\n    陆氏三代家主都极具雄韬伟略，以千金买官，以万金开路，更是在蛮夷南侵之时，倾尽家资招兵买马，拒十万蛮夷铁骑于侯关外，短短三年间，便一手扶持起了都护大将军——苏和，抗夷大将军——邓昌。\\n    以姻亲握住兵权后，陆氏子弟一路仕途平坦，百年来，人才辈出，更有陆云，陆羽等良将贤才。\\n    而今，已是雄踞渝、豫两地的世家阀门，这江南数万水军，便是掌握在这一代的陆家族长手中。\\n    朝廷无权，皇帝无兵，短短十年，南朝便形同虚设，各地封疆大使，世家阀门手握重兵，除了京都三省还在南朝皇族手中，其他俨然已经分地而治。\"",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "Error in handler ConsoleCallbackHandler, handleChainStart: Error: Parent run 069f9ad0-ca6a-401e-a353-2b87ea07d1e0 not found",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:refine_documents_chain > 4:chain:llm_chain > \u001b[1m5:llm:openai\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"Your job is to produce a final summary\\nWe have provided an existing summary up to a certain point: \\\" \\nThis book is uploaded by users to the storage space of i7wu.cn, a website that only provides TXT full set e-book storage and free download services. The copyright of the following works has no relation with the website. The book is called \\\"地藏心经\\\" and is written by 铸剑师无名.\\\"\\nWe have the opportunity to refine the existing summary\\n(only if needed) with some more context below.\\n------------\\n\\\"第一第十五章 天下势，渡江（一）\\n    “渝州陆家？！”\\n    虽然原本的那个秦逸，每日只知道苦读诗书，从未与商贾们打过交道，但是渝州陆家的名声，他还是知道。\\n    陆家三代为官，官至两江总督，五代经商，百年经营，家私何止千万，直至今朝，俨然已是江南一等士族大户。渝州陆氏以皮货起家，乃是西北之地数得上号的商户，西北之地所产的皮货，有三成经他们之手卖往江南。\\n    若只是如此，陆氏也不过是一头肥硕的羔羊，只待他人宰杀。\\n    陆氏三代家主都极具雄韬伟略，以千金买官，以万金开路，更是在蛮夷南侵之时，倾尽家资招兵买马，拒十万蛮夷铁骑于侯关外，短短三年间，便一手扶持起了都护大将军——苏和，抗夷大将军——邓昌。\\n    以姻亲握住兵权后，陆氏子弟一路仕途平坦，百年来，人才辈出，更有陆云，陆羽等良将贤才。\\n    而今，已是雄踞渝、豫两地的世家阀门，这江南数万水军，便是掌握在这一代的陆家族长手中。\\n    朝廷无权，皇帝无兵，短短十年，南朝便形同虚设，各地封疆大使，世家阀门手握重兵，除了京都三省还在南朝皇族手中，其他俨然已经分地而治。\\\"\\n------------\\n\\nGiven the new context, refine the original summary\\nIf the context isn't useful, return the original summary.\\n\\nREFINED SUMMARY:\"",
                                "  ]",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "Error in handler ConsoleCallbackHandler, handleLLMStart: Error: Parent run ae4beb07-eff5-4b4a-af42-b2d84dfffa2e not found",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:refine_documents_chain > 4:chain:llm_chain > \u001b[1m5:llm:openai\u001b[22m\u001b[39m] [12.15s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"\\nThis book is uploaded by users to the storage space of i7wu.cn, a website that only provides TXT full set e-book storage and free download services. The copyright of the following works has no relation with the website. The book is called \\\"地藏心经\\\" and is written by 铸剑师无名. It tells the story of the Lu family, who rose to power in the Jiangnan region, through their business in the trading of furs from the northwest. Over the course of a century, the Lu family produced many talented individuals, and eventually controlled the military forces in the regions of Yu and Yu. After a decade, the southern dynasty was nearly powerless and the regions were split into various factions, all under the control of the Lu family.\",",
                                "        \"generationInfo\": {",
                                "          \"finishReason\": \"stop\",",
                                "          \"logprobs\": null",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 170,",
                                "      \"promptTokens\": 1127,",
                                "      \"totalTokens\": 1297",
                                "    }",
                                "  }",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "Error in handler ConsoleCallbackHandler, handleLLMEnd: Error: No LLM run to end.",
                                "Error in handler ConsoleCallbackHandler, handleChainEnd: Error: No chain run to end.",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:refine_documents_chain > \u001b[1m6:chain:llm_chain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"existing_answer\": \"\\nThis book is uploaded by users to the storage space of i7wu.cn, a website that only provides TXT full set e-book storage and free download services. The copyright of the following works has no relation with the website. The book is called \\\"地藏心经\\\" and is written by 铸剑师无名. It tells the story of the Lu family, who rose to power in the Jiangnan region, through their business in the trading of furs from the northwest. Over the course of a century, the Lu family produced many talented individuals, and eventually controlled the military forces in the regions of Yu and Yu. After a decade, the southern dynasty was nearly powerless and the regions were split into various factions, all under the control of the Lu family.\",",
                                "  \"text\": \"西北，邓、李、苏、何、公孙五家世家阀门割据一方，联手共抗蛮夷合并后的金国。\\n    南方，陆、熊、刘、郑四家百年士族据守江南，与中山国相持已然数十载。\\n    东方，京都三省雄兵三十万，黑甲铁骑八千，时刻防范着秦国有所异动。（备注：黑甲铁骑配备长枪，马刀，黑铁重甲，所乘骑的乃是西域宛马，是南朝立国时便赫赫有名的百战铁骑。曾以八千黑甲铁骑破中山国十万雄兵而名动天下。）\\n    这些，便是张狂融合完原本那个‘秦逸’的记忆，而整理出的天下大势。\\n    **************************************************************************\\n    “少爷。这船都被陆家车行的人包下了。”\\n    不过一会儿，秦汉便略显沮丧地走了回来。渝州陆家势大，而今就连附属下面的陆家车行，身份也是水涨船高。自从秦逸父亲病逝后，秦家家道中落，与陆家比不得，况且此地也并非西北所属，秦家纵然还有些人脉，却也用不上。\\n    所以，为了避免麻烦，他也没敢去与陆家争船。\"",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "Error in handler ConsoleCallbackHandler, handleChainStart: Error: Parent run 069f9ad0-ca6a-401e-a353-2b87ea07d1e0 not found",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:refine_documents_chain > 6:chain:llm_chain > \u001b[1m7:llm:openai\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"Your job is to produce a final summary\\nWe have provided an existing summary up to a certain point: \\\"\\nThis book is uploaded by users to the storage space of i7wu.cn, a website that only provides TXT full set e-book storage and free download services. The copyright of the following works has no relation with the website. The book is called \\\"地藏心经\\\" and is written by 铸剑师无名. It tells the story of the Lu family, who rose to power in the Jiangnan region, through their business in the trading of furs from the northwest. Over the course of a century, the Lu family produced many talented individuals, and eventually controlled the military forces in the regions of Yu and Yu. After a decade, the southern dynasty was nearly powerless and the regions were split into various factions, all under the control of the Lu family.\\\"\\nWe have the opportunity to refine the existing summary\\n(only if needed) with some more context below.\\n------------\\n\\\"西北，邓、李、苏、何、公孙五家世家阀门割据一方，联手共抗蛮夷合并后的金国。\\n    南方，陆、熊、刘、郑四家百年士族据守江南，与中山国相持已然数十载。\\n    东方，京都三省雄兵三十万，黑甲铁骑八千，时刻防范着秦国有所异动。（备注：黑甲铁骑配备长枪，马刀，黑铁重甲，所乘骑的乃是西域宛马，是南朝立国时便赫赫有名的百战铁骑。曾以八千黑甲铁骑破中山国十万雄兵而名动天下。）\\n    这些，便是张狂融合完原本那个‘秦逸’的记忆，而整理出的天下大势。\\n    **************************************************************************\\n    “少爷。这船都被陆家车行的人包下了。”\\n    不过一会儿，秦汉便略显沮丧地走了回来。渝州陆家势大，而今就连附属下面的陆家车行，身份也是水涨船高。自从秦逸父亲病逝后，秦家家道中落，与陆家比不得，况且此地也并非西北所属，秦家纵然还有些人脉，却也用不上。\\n    所以，为了避免麻烦，他也没敢去与陆家争船。\\\"\\n------------\\n\\nGiven the new context, refine the original summary\\nIf the context isn't useful, return the original summary.\\n\\nREFINED SUMMARY:\"",
                                "  ]",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "Error in handler ConsoleCallbackHandler, handleLLMStart: Error: Parent run fc151a25-f6cd-4309-87ed-ca73753af012 not found",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:refine_documents_chain > 6:chain:llm_chain > \u001b[1m7:llm:openai\u001b[22m\u001b[39m] [14.44s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \" \\nThis book is uploaded by users to the storage space of i7wu.cn, a website that only provides TXT full set e-book storage and free download services. The copyright of the following works has no relation with the website. The book is called \\\"地藏心经\\\" and is written by 铸剑师无名. It tells the story of the Lu family, who rose to power in the Jiangnan region, through their business in the trading of furs from the northwest. Over the course of a century, the Lu family produced many talented individuals and eventually controlled the military forces in the regions of Yu and Yu. This caused the southern dynasty to become nearly powerless, leading to the regions being split into various factions, all under the control of the Lu family. The Lu family was able to establish dominance over the other families in the area, including the Deng, Li, Su, He, and Gongsun families in the northwest, the Lu, Xiong, Liu, and Zheng families in the south, and the three provinces in the east. They were even able to secure a boat from the Lu family's car business in Yuzhou, despite their weakened status.\",",
                                "        \"generationInfo\": {",
                                "          \"finishReason\": \"stop\",",
                                "          \"logprobs\": null",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 253,",
                                "      \"promptTokens\": 1034,",
                                "      \"totalTokens\": 1287",
                                "    }",
                                "  }",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "Error in handler ConsoleCallbackHandler, handleLLMEnd: Error: No LLM run to end.",
                                "Error in handler ConsoleCallbackHandler, handleChainEnd: Error: No chain run to end.",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:refine_documents_chain\u001b[22m\u001b[39m] [33.70s] Exiting Chain run with output: {",
                                "  \"output_text\": \" \\nThis book is uploaded by users to the storage space of i7wu.cn, a website that only provides TXT full set e-book storage and free download services. The copyright of the following works has no relation with the website. The book is called \\\"地藏心经\\\" and is written by 铸剑师无名. It tells the story of the Lu family, who rose to power in the Jiangnan region, through their business in the trading of furs from the northwest. Over the course of a century, the Lu family produced many talented individuals and eventually controlled the military forces in the regions of Yu and Yu. This caused the southern dynasty to become nearly powerless, leading to the regions being split into various factions, all under the control of the Lu family. The Lu family was able to establish dominance over the other families in the area, including the Deng, Li, Su, He, and Gongsun families in the northwest, the Lu, Xiong, Liu, and Zheng families in the south, and the three provinces in the east. They were even able to secure a boat from the Lu family's car business in Yuzhou, despite their weakened status.\"",
                                "}",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "// 使用内存向量索引数据库构建问答机器人\nimport { OpenAI } from 'langchain/llms/openai';\nimport { OpenAIEmbeddings } from 'langchain/embeddings/openai';\nimport { TextLoader } from 'langchain/document_loaders/fs/text';\nimport { RecursiveCharacterTextSplitter } from 'langchain/text_splitter';\nimport { MemoryVectorStore } from 'langchain/vectorstores/memory';\nimport { VectorDBQAChain } from 'langchain/chains';\n\n// 初始化文本分割器\nconst splitter = new RecursiveCharacterTextSplitter({\n  chunkSize: 500,\n  chunkOverlap: 0,\n});\n\n// 导入文本\nconst loader = new TextLoader('data/large_text.txt');\nconst docs = await loader.loadAndSplit(splitter);\nconsole.log('[ # of split documents ] >', docs.length);\n\n// 加载 OpenAI 模型\nconst model = new OpenAI();\nconst embeddings = new OpenAIEmbeddings();\n\n// 创建向量索引数据库（为了快速演示，只导入前 10 段）\nconst vectorStore = await MemoryVectorStore.fromDocuments(docs.slice(0, 10), embeddings);\n\n// 创建并执行问答链\nconst chain = VectorDBQAChain.fromLLM(model, vectorStore, {\n  k: 1,\n  returnSourceDocuments: true,\n  verbose: true,\n});\nawait chain.call({ query: '秦逸是谁？' });"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "[ # of documents ] > 360",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "text/plain",
                            "value": [
                                "{",
                                "  text: \u001b[32m' 秦逸是秦家少爷，一个晋中秦家的家族成员。'\u001b[39m,",
                                "  sourceDocuments: [",
                                "    Document {",
                                "      pageContent: \u001b[32m'“敢问，可是秦逸公子？！”中年商人对着秦逸又是一个大礼，声音颇为颤抖地说道。此番回程，他便听说了秦家少爷要前往渝州，却想不到自己居然正好遇上！\\n'\u001b[39m +",
                                "        \u001b[32m'    “五代行善，何其不易！夫天下之人，独晋中秦家也！”……\\n'\u001b[39m +",
                                "        \u001b[32m'    秦家善名，至今已然百年有余。\\n'\u001b[39m +",
                                "        \u001b[32m'    “嗯。”秦逸点头，并未多说。一路行来，他已经陆续感受到了秦家在这个世界上的声望。\\n'\u001b[39m +",
                                "        \u001b[32m'    一世行善容易，但是五代行善，中原数千年来，独此一家。就连数十年前，蛮夷赫连氏族入侵中原，都刻意避开了晋中秦家。在草原蛮族的教义中，屠戮真正的善人，会被狼神抛弃，灵魂永世不得安息。\\n'\u001b[39m +",
                                "        \u001b[32m'    ************************************************************************\\n'\u001b[39m +",
                                "        \u001b[32m'    就在秦逸准备寻一处清净地，安安静静的等待陆家车行的人先走时，远处，一团人簇拥着一个青衫老者往这边走来。而为首的，正是昨日在路上遇到的那个满脸扎须的壮年汉子。\\n'\u001b[39m +",
                                "        \u001b[32m'    “那便是陆家车行的管事。”一旁的中年商人适时的报出了那位青衫老者的身份。\\n'\u001b[39m +",
                                "        \u001b[32m'    “陆氏车行？管事？”'\u001b[39m,",
                                "      metadata: \u001b[36m[Object]\u001b[39m",
                                "    }",
                                "  ]",
                                "}"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "// 使用 Pinecone 向量索引库构建问答机器人\nimport { OpenAI } from 'langchain/llms/openai';\nimport { OpenAIEmbeddings } from 'langchain/embeddings/openai';\nimport { TextLoader } from 'langchain/document_loaders/fs/text';\nimport { RecursiveCharacterTextSplitter } from 'langchain/text_splitter';\nimport { VectorDBQAChain } from 'langchain/chains';\nimport { PineconeStore } from 'langchain/vectorstores/pinecone';\nimport { PineconeClient } from '@pinecone-database/pinecone';\n\n// 初始化文本分割器\nconst splitter = new RecursiveCharacterTextSplitter({\n  chunkSize: 500,\n  chunkOverlap: 0,\n});\n\n// 导入文本\nconst loader = new TextLoader('data/large_text.txt');\nconst docs = await loader.loadAndSplit(splitter);\nconsole.log('[ # of split documents ] >', docs.length);\n\n// 加载 OpenAI 模型\nconst model = new OpenAI();\nconst embeddings = new OpenAIEmbeddings();\n\n// 初始化 Pinecone\nconst client = new PineconeClient();\nawait client.init({\n  apiKey: process.env.PINECONE_API_KEY!,\n  environment: process.env.PINECONE_ENVIRONMENT!,\n});\nconst pineconeIndex = client.Index(process.env.PINECONE_INDEX!);\n\n// 向 Pinecone 导入数据（为了快速演示，只导入前 10 段）\n// await PineconeStore.fromDocuments(docs.slice(0, 10), embeddings, {\n//   pineconeIndex,\n// });\n\n// 初始化向量索引\nconst vectorStore = await PineconeStore.fromExistingIndex(embeddings, { pineconeIndex });\n\n// 创建并执行问答链\nconst chain = VectorDBQAChain.fromLLM(model, vectorStore, {\n  k: 1,\n  returnSourceDocuments: true,\n  verbose: true,\n});\nawait chain.call({ query: '秦逸是谁？' });"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "[ # of split documents ] > 360",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:vector_db_qa\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"query\": \"秦逸是谁？\"",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:vector_db_qa > 2:chain:stuff_documents_chain > 3:chain:llm_chain > \u001b[1m4:llm:openai\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n“敢问，可是秦逸公子？！”中年商人对着秦逸又是一个大礼，声音颇为颤抖地说道。此番回程，他便听说了秦家少爷要前往渝州，却想不到自己居然正好遇上！\\n    “五代行善，何其不易！夫天下之人，独晋中秦家也！”……\\n    秦家善名，至今已然百年有余。\\n    “嗯。”秦逸点头，并未多说。一路行来，他已经陆续感受到了秦家在这个世界上的声望。\\n    一世行善容易，但是五代行善，中原数千年来，独此一家。就连数十年前，蛮夷赫连氏族入侵中原，都刻意避开了晋中秦家。在草原蛮族的教义中，屠戮真正的善人，会被狼神抛弃，灵魂永世不得安息。\\n    ************************************************************************\\n    就在秦逸准备寻一处清净地，安安静静的等待陆家车行的人先走时，远处，一团人簇拥着一个青衫老者往这边走来。而为首的，正是昨日在路上遇到的那个满脸扎须的壮年汉子。\\n    “那便是陆家车行的管事。”一旁的中年商人适时的报出了那位青衫老者的身份。\\n    “陆氏车行？管事？”\\n\\nQuestion: 秦逸是谁？\\nHelpful Answer:\"",
                                "  ]",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:vector_db_qa\u001b[22m\u001b[39m] [6.17s] Exiting Chain run with output: {",
                                "  \"text\": \" 秦逸是晋中秦家的少爷，他正在前往渝州。\",",
                                "  \"sourceDocuments\": [",
                                "    {",
                                "      \"pageContent\": \"“敢问，可是秦逸公子？！”中年商人对着秦逸又是一个大礼，声音颇为颤抖地说道。此番回程，他便听说了秦家少爷要前往渝州，却想不到自己居然正好遇上！\\n    “五代行善，何其不易！夫天下之人，独晋中秦家也！”……\\n    秦家善名，至今已然百年有余。\\n    “嗯。”秦逸点头，并未多说。一路行来，他已经陆续感受到了秦家在这个世界上的声望。\\n    一世行善容易，但是五代行善，中原数千年来，独此一家。就连数十年前，蛮夷赫连氏族入侵中原，都刻意避开了晋中秦家。在草原蛮族的教义中，屠戮真正的善人，会被狼神抛弃，灵魂永世不得安息。\\n    ************************************************************************\\n    就在秦逸准备寻一处清净地，安安静静的等待陆家车行的人先走时，远处，一团人簇拥着一个青衫老者往这边走来。而为首的，正是昨日在路上遇到的那个满脸扎须的壮年汉子。\\n    “那便是陆家车行的管事。”一旁的中年商人适时的报出了那位青衫老者的身份。\\n    “陆氏车行？管事？”\",",
                                "      \"metadata\": {",
                                "        \"loc.lines.from\": 34,",
                                "        \"loc.lines.to\": 42,",
                                "        \"source\": \"data/large_text.txt\"",
                                "      }",
                                "    }",
                                "  ]",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "text/plain",
                            "value": [
                                "{",
                                "  text: \u001b[32m' 秦逸是晋中秦家的少爷，他正在前往渝州。'\u001b[39m,",
                                "  sourceDocuments: [",
                                "    Document {",
                                "      pageContent: \u001b[32m'“敢问，可是秦逸公子？！”中年商人对着秦逸又是一个大礼，声音颇为颤抖地说道。此番回程，他便听说了秦家少爷要前往渝州，却想不到自己居然正好遇上！\\n'\u001b[39m +",
                                "        \u001b[32m'    “五代行善，何其不易！夫天下之人，独晋中秦家也！”……\\n'\u001b[39m +",
                                "        \u001b[32m'    秦家善名，至今已然百年有余。\\n'\u001b[39m +",
                                "        \u001b[32m'    “嗯。”秦逸点头，并未多说。一路行来，他已经陆续感受到了秦家在这个世界上的声望。\\n'\u001b[39m +",
                                "        \u001b[32m'    一世行善容易，但是五代行善，中原数千年来，独此一家。就连数十年前，蛮夷赫连氏族入侵中原，都刻意避开了晋中秦家。在草原蛮族的教义中，屠戮真正的善人，会被狼神抛弃，灵魂永世不得安息。\\n'\u001b[39m +",
                                "        \u001b[32m'    ************************************************************************\\n'\u001b[39m +",
                                "        \u001b[32m'    就在秦逸准备寻一处清净地，安安静静的等待陆家车行的人先走时，远处，一团人簇拥着一个青衫老者往这边走来。而为首的，正是昨日在路上遇到的那个满脸扎须的壮年汉子。\\n'\u001b[39m +",
                                "        \u001b[32m'    “那便是陆家车行的管事。”一旁的中年商人适时的报出了那位青衫老者的身份。\\n'\u001b[39m +",
                                "        \u001b[32m'    “陆氏车行？管事？”'\u001b[39m,",
                                "      metadata: \u001b[36m[Object]\u001b[39m",
                                "    }",
                                "  ]",
                                "}"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "// 使用 Zapier NLA 发送邮件\nimport { OpenAI } from 'langchain/llms/openai';\nimport { ZapierNLAWrapper } from 'langchain/tools';\nimport { initializeAgentExecutorWithOptions, ZapierToolKit } from 'langchain/agents';\n\n// 初始化 OpenAI 模型\nconst model = new OpenAI({ temperature: 0 });\n\n// 初始化 Zapier NLA 工具集\nconst zapier = new ZapierNLAWrapper();\nconst toolkit = await ZapierToolKit.fromZapierNLAWrapper(zapier);\n\nconst executor = await initializeAgentExecutorWithOptions(toolkit.tools, model, {\n  agentType: 'zero-shot-react-description',\n  verbose: true,\n});\nconsole.log('Agent loaded with below tools:');\n\n// 查看已经在 Zapier 中配置的工具\ntoolkit.tools.forEach((tool) => {\n  console.log('[ tool.name ] >', tool.name);\n  console.log('[ tool.description ] >', tool.description);\n})\n\n// 启动代理执行命令\nconst input = `请总结最后一封\"jsw@peterc.org\"发给我的邮件。并将总结翻译成中文后发送给\"zhanghaili@gmail.com\"`;\nconsole.log(`Executing with input \"${input}\"...`);\n\nawait executor.call({ input });\n"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "Agent loaded with below tools:",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:agent_executor > 2:chain:llm_chain > \u001b[1m3:llm:openai\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"Answer the following questions as best you can. You have access to the following tools:\\n\\nGmail: Send Email: A wrapper around Zapier NLA actions. The input to this tool is a natural language instruction, for example \\\"get the latest email from my bank\\\" or \\\"send a slack message to the #general channel\\\". Each tool will have params associated with it that are specified as a list. You MUST take into account the params when creating the instruction. For example, if the params are ['Message_Text', 'Channel'], your instruction should be something like 'send a slack message to the #general channel with the text hello world'. Another example: if the params are ['Calendar', 'Search_Term'], your instruction should be something like 'find the meeting in my personal calendar at 3pm'. Do not make up params, they will be explicitly specified in the tool description. If you do not have enough information to fill in the params, just say 'not enough information provided in the instruction, missing <param>'. If you get a none or null response, STOP EXECUTION, do not try to another tool! This tool specifically used for: Gmail: Send Email, and has params: [\\\"To\\\",\\\"Body\\\",\\\"Subject\\\",\\\"Cc\\\"]\\nGmail: Find Email: A wrapper around Zapier NLA actions. The input to this tool is a natural language instruction, for example \\\"get the latest email from my bank\\\" or \\\"send a slack message to the #general channel\\\". Each tool will have params associated with it that are specified as a list. You MUST take into account the params when creating the instruction. For example, if the params are ['Message_Text', 'Channel'], your instruction should be something like 'send a slack message to the #general channel with the text hello world'. Another example: if the params are ['Calendar', 'Search_Term'], your instruction should be something like 'find the meeting in my personal calendar at 3pm'. Do not make up params, they will be explicitly specified in the tool description. If you do not have enough information to fill in the params, just say 'not enough information provided in the instruction, missing <param>'. If you get a none or null response, STOP EXECUTION, do not try to another tool! This tool specifically used for: Gmail: Find Email, and has params: [\\\"Search_String\\\"]\\n\\nUse the following format in your response:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Gmail: Send Email,Gmail: Find Email]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: 请用总结最后一封\\\"jsw@peterc.org\\\"发给我的邮件。并将总结翻译成中文后发送给\\\"zhanghaili@gmail.com\\\"\\nThought:\"",
                                "  ]",
                                "}",
                                "\u001b[32m[tool/start]\u001b[39m [\u001b[90m1:chain:agent_executor > \u001b[1m4:tool:Gmail: Find Email\u001b[22m\u001b[39m] Entering Tool run with input: \"Find the latest email from jsw@peterc.org\"",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:agent_executor > 5:chain:llm_chain > \u001b[1m6:llm:openai\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"Answer the following questions as best you can. You have access to the following tools:\\n\\nGmail: Send Email: A wrapper around Zapier NLA actions. The input to this tool is a natural language instruction, for example \\\"get the latest email from my bank\\\" or \\\"send a slack message to the #general channel\\\". Each tool will have params associated with it that are specified as a list. You MUST take into account the params when creating the instruction. For example, if the params are ['Message_Text', 'Channel'], your instruction should be something like 'send a slack message to the #general channel with the text hello world'. Another example: if the params are ['Calendar', 'Search_Term'], your instruction should be something like 'find the meeting in my personal calendar at 3pm'. Do not make up params, they will be explicitly specified in the tool description. If you do not have enough information to fill in the params, just say 'not enough information provided in the instruction, missing <param>'. If you get a none or null response, STOP EXECUTION, do not try to another tool! This tool specifically used for: Gmail: Send Email, and has params: [\\\"To\\\",\\\"Body\\\",\\\"Subject\\\",\\\"Cc\\\"]\\nGmail: Find Email: A wrapper around Zapier NLA actions. The input to this tool is a natural language instruction, for example \\\"get the latest email from my bank\\\" or \\\"send a slack message to the #general channel\\\". Each tool will have params associated with it that are specified as a list. You MUST take into account the params when creating the instruction. For example, if the params are ['Message_Text', 'Channel'], your instruction should be something like 'send a slack message to the #general channel with the text hello world'. Another example: if the params are ['Calendar', 'Search_Term'], your instruction should be something like 'find the meeting in my personal calendar at 3pm'. Do not make up params, they will be explicitly specified in the tool description. If you do not have enough information to fill in the params, just say 'not enough information provided in the instruction, missing <param>'. If you get a none or null response, STOP EXECUTION, do not try to another tool! This tool specifically used for: Gmail: Find Email, and has params: [\\\"Search_String\\\"]\\n\\nUse the following format in your response:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Gmail: Send Email,Gmail: Find Email]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: 请用总结最后一封\\\"jsw@peterc.org\\\"发给我的邮件。并将总结翻译成中文后发送给\\\"zhanghaili@gmail.com\\\"\\nThought: I need to find the latest email from jsw@peterc.org and then summarize it and translate it into Chinese before sending it to zhanghaili@gmail.com\\nAction: Gmail: Find Email\\nAction Input: Find the latest email from jsw@peterc.org\\nObservation: {\\\"from__email\\\":\\\"jsw@peterc.org\\\",\\\"from__name\\\":\\\"JavaScript Weekly\\\",\\\"date\\\":\\\"Thu, 11 May 2023 16:42:47 +0000 (UTC)\\\",\\\"to__emails\\\":\\\"zhanghaili@gmail.com\\\",\\\"message_url\\\":\\\"https://mail.google.com/mail/u/0/#inbox/1880bb1954db6fcf\\\",\\\"attachment_count\\\":\\\"0\\\",\\\"message_id\\\":\\\"1880bb1954db6fcf\\\",\\\"body_plain\\\":\\\"Should MS write Windows 12 in Svelte? It's possible, but it's too early to tell. The JavaScript ecosystem is delightfully weird and the new features coming in ECMAScript 2023 could make it a viable option. Full stack for front-end engineers with Jem Young (Netflix) is a great way to learn more.\\\"}\\nThought:\"",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:agent_executor > 5:chain:llm_chain > \u001b[1m6:llm:openai\u001b[22m\u001b[39m] [20.78s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \" I now need to summarize the email and translate it into Chinese\\nAction: Gmail: Send Email\\nAction Input: Send an email to zhanghaili@gmail.com with the subject \\\"Summary of Latest Email from jsw@peterc.org\\\" and the body \\\"MS 可能会用 Svelte 写 Windows 12，但现在还为时尚早。JavaScript 生态系统非常有趣，ECMAScript 2023 中的新特性可能会使其成为一个可行的选择。Netflix 的 Jem Young 提供的全栈前端工程师培训是一个很好的学习机会。\\\"\",",
                                "        \"generationInfo\": {",
                                "          \"finishReason\": \"stop\",",
                                "          \"logprobs\": null",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 217,",
                                "      \"promptTokens\": 952,",
                                "      \"totalTokens\": 1169",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:agent_executor > \u001b[1m5:chain:llm_chain\u001b[22m\u001b[39m] [20.78s] Exiting Chain run with output: {",
                                "  \"text\": \" I now need to summarize the email and translate it into Chinese\\nAction: Gmail: Send Email\\nAction Input: Send an email to zhanghaili@gmail.com with the subject \\\"Summary of Latest Email from jsw@peterc.org\\\" and the body \\\"MS 可能会用 Svelte 写 Windows 12，但现在还为时尚早。JavaScript 生态系统非常有趣，ECMAScript 2023 中的新特性可能会使其成为一个可行的选择。Netflix 的 Jem Young 提供的全栈前端工程师培训是一个很好的学习机会。\\\"\"",
                                "}",
                                "\u001b[34m[agent/action]\u001b[39m [\u001b[90m\u001b[1m1:chain:agent_executor\u001b[22m\u001b[39m] Agent selected action: {",
                                "  \"tool\": \"Gmail: Send Email\",",
                                "  \"toolInput\": \"Send an email to zhanghaili@gmail.com with the subject \\\"Summary of Latest Email from jsw@peterc.org\\\" and the body \\\"MS 可能会用 Svelte 写 Windows 12，但现在还为时尚早。JavaScript 生态系统非常有趣，ECMAScript 2023 中的新特性可能会使其成为一个可行的选择。Netflix 的 Jem Young 提供的全栈前端工程师培训是一个很好的学习机会。\",",
                                "  \"log\": \" I now need to summarize the email and translate it into Chinese\\nAction: Gmail: Send Email\\nAction Input: Send an email to zhanghaili@gmail.com with the subject \\\"Summary of Latest Email from jsw@peterc.org\\\" and the body \\\"MS 可能会用 Svelte 写 Windows 12，但现在还为时尚早。JavaScript 生态系统非常有趣，ECMAScript 2023 中的新特性可能会使其成为一个可行的选择。Netflix 的 Jem Young 提供的全栈前端工程师培训是一个很好的学习机会。\\\"\"",
                                "}",
                                "\u001b[32m[tool/start]\u001b[39m [\u001b[90m1:chain:agent_executor > \u001b[1m7:tool:Gmail: Send Email\u001b[22m\u001b[39m] Entering Tool run with input: \"Send an email to zhanghaili@gmail.com with the subject \"Summary of Latest Email from jsw@peterc.org\" and the body \"MS 可能会用 Svelte 写 Windows 12，但现在还为时尚早。JavaScript 生态系统非常有趣，ECMAScript 2023 中的新特性可能会使其成为一个可行的选择。Netflix 的 Jem Young 提供的全栈前端工程师培训是一个很好的学习机会。\"",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:agent_executor > 8:chain:llm_chain > \u001b[1m9:llm:openai\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"Answer the following questions as best you can. You have access to the following tools:\\n\\nGmail: Send Email: A wrapper around Zapier NLA actions. The input to this tool is a natural language instruction, for example \\\"get the latest email from my bank\\\" or \\\"send a slack message to the #general channel\\\". Each tool will have params associated with it that are specified as a list. You MUST take into account the params when creating the instruction. For example, if the params are ['Message_Text', 'Channel'], your instruction should be something like 'send a slack message to the #general channel with the text hello world'. Another example: if the params are ['Calendar', 'Search_Term'], your instruction should be something like 'find the meeting in my personal calendar at 3pm'. Do not make up params, they will be explicitly specified in the tool description. If you do not have enough information to fill in the params, just say 'not enough information provided in the instruction, missing <param>'. If you get a none or null response, STOP EXECUTION, do not try to another tool! This tool specifically used for: Gmail: Send Email, and has params: [\\\"To\\\",\\\"Body\\\",\\\"Subject\\\",\\\"Cc\\\"]\\nGmail: Find Email: A wrapper around Zapier NLA actions. The input to this tool is a natural language instruction, for example \\\"get the latest email from my bank\\\" or \\\"send a slack message to the #general channel\\\". Each tool will have params associated with it that are specified as a list. You MUST take into account the params when creating the instruction. For example, if the params are ['Message_Text', 'Channel'], your instruction should be something like 'send a slack message to the #general channel with the text hello world'. Another example: if the params are ['Calendar', 'Search_Term'], your instruction should be something like 'find the meeting in my personal calendar at 3pm'. Do not make up params, they will be explicitly specified in the tool description. If you do not have enough information to fill in the params, just say 'not enough information provided in the instruction, missing <param>'. If you get a none or null response, STOP EXECUTION, do not try to another tool! This tool specifically used for: Gmail: Find Email, and has params: [\\\"Search_String\\\"]\\n\\nUse the following format in your response:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Gmail: Send Email,Gmail: Find Email]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: 请用总结最后一封\\\"jsw@peterc.org\\\"发给我的邮件。并将总结翻译成中文后发送给\\\"zhanghaili@gmail.com\\\"\\nThought: I need to find the latest email from jsw@peterc.org and then summarize it and translate it into Chinese before sending it to zhanghaili@gmail.com\\nAction: Gmail: Find Email\\nAction Input: Find the latest email from jsw@peterc.org\\nObservation: {\\\"from__email\\\":\\\"jsw@peterc.org\\\",\\\"from__name\\\":\\\"JavaScript Weekly\\\",\\\"date\\\":\\\"Thu, 11 May 2023 16:42:47 +0000 (UTC)\\\",\\\"to__emails\\\":\\\"zhanghaili@gmail.com\\\",\\\"message_url\\\":\\\"https://mail.google.com/mail/u/0/#inbox/1880bb1954db6fcf\\\",\\\"attachment_count\\\":\\\"0\\\",\\\"message_id\\\":\\\"1880bb1954db6fcf\\\",\\\"body_plain\\\":\\\"Should MS write Windows 12 in Svelte? It's possible, but it's too early to tell. The JavaScript ecosystem is delightfully weird and the new features coming in ECMAScript 2023 could make it a viable option. Full stack for front-end engineers with Jem Young (Netflix) is a great way to learn more.\\\"}\\nThought: I now need to summarize the email and translate it into Chinese\\nAction: Gmail: Send Email\\nAction Input: Send an email to zhanghaili@gmail.com with the subject \\\"Summary of Latest Email from jsw@peterc.org\\\" and the body \\\"MS 可能会用 Svelte 写 Windows 12，但现在还为时尚早。JavaScript 生态系统非常有趣，ECMAScript 2023 中的新特性可能会使其成为一个可行的选择。Netflix 的 Jem Young 提供的全栈前端工程师培训是一个很好的学习机会。\\\"\\nObservation: {\\\"threadId\\\":\\\"1881544c0d1cb975\\\",\\\"labelIds\\\":\\\"UNREAD, SENT, INBOX\\\"}\\nThought:\"",
                                "  ]",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:agent_executor > \u001b[1m8:chain:llm_chain\u001b[22m\u001b[39m] [18.84s] Exiting Chain run with output: {",
                                "  \"text\": \" I now know the final answer\\nFinal Answer: An email has been sent to zhanghaili@gmail.com with the subject \\\"Summary of Latest Email from jsw@peterc.org\\\" and the body \\\"MS 可能会用 Svelte 写 Windows 12，但现在还为时尚早。JavaScript 生态系统非常有趣，ECMAScript 2023 中的新特性可能会使其成为一个可行的选择。Netflix 的 Jem Young 提供的全栈前端工程师培训是一个很好的学习机会。\\\"\"",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:agent_executor\u001b[22m\u001b[39m] [69.99s] Exiting Chain run with output: {",
                                "  \"output\": \"An email has been sent to zhanghaili@gmail.com with the subject \\\"Summary of Latest Email from jsw@peterc.org\\\" and the body \\\"MS 可能会用 Svelte 写 Windows 12，但现在还为时尚早。JavaScript 生态系统非常有趣，ECMAScript 2023 中的新特性可能会使其成为一个可行的选择。Netflix 的 Jem Young 提供的全栈前端工程师培训是一个很好的学习机会。\\\"\"",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "text/plain",
                            "value": [
                                "{",
                                "  output: \u001b[32m'An email has been sent to zhanghaili@gmail.com with the subject \"Summary of Latest Email from jsw@peterc.org\" and the body \"MS 可能会用 Svelte 写 Windows 12，但现在还为时尚早。JavaScript 生态系统非常有趣，ECMAScript 2023 中的新特性可能会使其成为一个可行的选择。Netflix 的 Jem Young 提供的全栈前端工程师培训是一个很好的学习机会。\"'\u001b[39m",
                                "}"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "// 使用顺序的任务链\nimport { SimpleSequentialChain, LLMChain } from 'langchain/chains';\nimport { OpenAI } from 'langchain/llms/openai';\nimport { PromptTemplate } from 'langchain/prompts';\n\n// This is an LLMChain to write a synopsis given a title of a play.\nconst llm = new OpenAI({ temperature: 0 });\nconst template = `You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n\n  Title: {title}\n  Playwright: This is a synopsis for the above play:`;\nconst promptTemplate = new PromptTemplate({\n  template,\n  inputVariables: ['title'],\n});\nconst synopsisChain = new LLMChain({ llm, prompt: promptTemplate });\n\n// This is an LLMChain to write a review of a play given a synopsis.\nconst reviewLLM = new OpenAI({ temperature: 0 });\nconst reviewTemplate = `You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n  \n  Play Synopsis:\n  {synopsis}\n  Review from a New York Times play critic of the above play:`;\nconst reviewPromptTemplate = new PromptTemplate({\n  template: reviewTemplate,\n  inputVariables: ['synopsis'],\n});\nconst reviewChain = new LLMChain({\n  llm: reviewLLM,\n  prompt: reviewPromptTemplate,\n});\n\nconst overallChain = new SimpleSequentialChain({\n  chains: [synopsisChain, reviewChain],\n  verbose: true,\n});\nawait overallChain.run('Tragedy at sunset on the beach');"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:simple_sequential_chain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"Tragedy at sunset on the beach\"",
                                "}",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:simple_sequential_chain > \u001b[1m2:chain:llm_chain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"title\": \"Tragedy at sunset on the beach\"",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:simple_sequential_chain > 2:chain:llm_chain > \u001b[1m3:llm:openai\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\\n\\n  Title: Tragedy at sunset on the beach\\n  Playwright: This is a synopsis for the above play:\"",
                                "  ]",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:simple_sequential_chain > 4:chain:llm_chain > \u001b[1m5:llm:openai\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\\n  \\n  Play Synopsis:\\n  \\n\\nTragedy at Sunset on the Beach is a story of love, loss, and redemption. It follows the story of two young lovers, Jack and Jill, who meet on a beach at sunset. They quickly fall in love and plan to marry, but their plans are shattered when Jack is tragically killed in a car accident. \\n\\nJill is left devastated and struggles to cope with her grief. She finds solace in the company of her best friend, Sarah, who helps her to come to terms with her loss. As Jill begins to heal, she discovers that Jack had left her a letter before his death, which reveals a secret that changes everything. \\n\\nJill must now make a difficult decision: to accept the truth and move on with her life, or to remain in the past and never find closure. In the end, Jill finds the strength to forgive and move forward, and discovers that love can still be found in the most unexpected places.\\n  Review from a New York Times play critic of the above play:\"",
                                "  ]",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:simple_sequential_chain > \u001b[1m4:chain:llm_chain\u001b[22m\u001b[39m] [12.64s] Exiting Chain run with output: {",
                                "  \"text\": \"\\n\\nTragedy at Sunset on the Beach is a powerful and moving story of love, loss, and redemption. The play follows the story of two young lovers, Jack and Jill, whose plans for a future together are tragically cut short when Jack is killed in a car accident. The audience is taken on an emotional journey as Jill struggles to cope with her grief and eventually finds the strength to forgive and move forward.\\n\\nThe performances of the two leads, Jack and Jill, are particularly noteworthy. They bring a depth of emotion to their characters that is both heartbreaking and inspiring. The supporting cast also does an excellent job of conveying the complexity of the characters’ relationships and the difficult decisions they must make.\\n\\nOverall, Tragedy at Sunset on the Beach is a touching and thought-provoking play that will leave audiences moved and inspired. It is a must-see for anyone looking for a powerful and meaningful theatrical experience.\"",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:simple_sequential_chain\u001b[22m\u001b[39m] [26.82s] Exiting Chain run with output: {",
                                "  \"output\": \"\\n\\nTragedy at Sunset on the Beach is a powerful and moving story of love, loss, and redemption. The play follows the story of two young lovers, Jack and Jill, whose plans for a future together are tragically cut short when Jack is killed in a car accident. The audience is taken on an emotional journey as Jill struggles to cope with her grief and eventually finds the strength to forgive and move forward.\\n\\nThe performances of the two leads, Jack and Jill, are particularly noteworthy. They bring a depth of emotion to their characters that is both heartbreaking and inspiring. The supporting cast also does an excellent job of conveying the complexity of the characters’ relationships and the difficult decisions they must make.\\n\\nOverall, Tragedy at Sunset on the Beach is a touching and thought-provoking play that will leave audiences moved and inspired. It is a must-see for anyone looking for a powerful and meaningful theatrical experience.\"",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "text/plain",
                            "value": [
                                "\u001b[32m'\\n'\u001b[39m +",
                                "  \u001b[32m'\\n'\u001b[39m +",
                                "  \u001b[32m'Tragedy at Sunset on the Beach is a powerful and moving story of love, loss, and redemption. The play follows the story of two young lovers, Jack and Jill, whose plans for a future together are tragically cut short when Jack is killed in a car accident. The audience is taken on an emotional journey as Jill struggles to cope with her grief and eventually finds the strength to forgive and move forward.\\n'\u001b[39m +",
                                "  \u001b[32m'\\n'\u001b[39m +",
                                "  \u001b[32m'The performances of the two leads, Jack and Jill, are particularly noteworthy. They bring a depth of emotion to their characters that is both heartbreaking and inspiring. The supporting cast also does an excellent job of conveying the complexity of the characters’ relationships and the difficult decisions they must make.\\n'\u001b[39m +",
                                "  \u001b[32m'\\n'\u001b[39m +",
                                "  \u001b[32m'Overall, Tragedy at Sunset on the Beach is a touching and thought-provoking play that will leave audiences moved and inspired. It is a must-see for anyone looking for a powerful and meaningful theatrical experience.'\u001b[39m"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "// 使用格式化输出输出\nimport { OpenAI } from \"langchain/llms/openai\";\nimport { PromptTemplate } from \"langchain/prompts\";\nimport { StructuredOutputParser } from \"langchain/output_parsers\";\n\n// With a `StructuredOutputParser` we can define a schema for the output.\nconst parser = StructuredOutputParser.fromNamesAndDescriptions({\n  answer: \"answer to the user's question\",\n  source: \"source used to answer the user's question, should be a website.\",\n});\n\nconst formatInstructions = parser.getFormatInstructions();\n\nconst prompt = new PromptTemplate({\n  template:\n    \"Answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n  inputVariables: [\"question\"],\n  partialVariables: { format_instructions: formatInstructions },\n});\n\nconst model = new OpenAI({ temperature: 0 });\n\nconst input = await prompt.format({\n  question: \"What is the capital of France?\",\n});\nconst response = await model.call(input);\nconsole.log('[ response ] >', response)\n\n\nconst output = await parser.parse(response);\nconsole.log('[ output ] >', output);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "[ response ] > ",
                                "",
                                "{\"answer\": \"Paris\", \"source\": \"https://en.wikipedia.org/wiki/Paris\"}",
                                "[ output ] > { answer: 'Paris', source: 'https://en.wikipedia.org/wiki/Paris' }",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "// 使用 Memory 实现一个带记忆的对话机器人\nimport { OpenAI } from 'langchain/llms/openai';\nimport { ConversationSummaryMemory } from 'langchain/memory';\nimport { LLMChain } from 'langchain/chains';\nimport { PromptTemplate } from 'langchain/prompts';\n\nconst memory = new ConversationSummaryMemory({\n  memoryKey: 'chat_history',\n  llm: new OpenAI({ modelName: 'gpt-3.5-turbo', temperature: 0 }),\n});\n\nconst model = new OpenAI({ temperature: 0.9 });\nconst prompt = PromptTemplate.fromTemplate(`The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n{chat_history}\nHuman: {input}\nAI:`);\nconst chain = new LLMChain({ llm: model, prompt, memory });\n\nconst res1 = await chain.call({ input: \"Hi! I'm Jim.\" });\nconsole.log({ res1, memory: await memory.loadMemoryVariables({}) });\n\nconst res2 = await chain.call({ input: \"What's my name?\" });\nconsole.log({ res2, memory: await memory.loadMemoryVariables({}) });"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "{",
                                "  res1: {",
                                "    text: \" Hi Jim! I'm AI. It's nice to meet you. Can I ask you a question?\"",
                                "  },",
                                "  memory: {",
                                "    chat_history: 'The human introduces himself as Jim and the AI greets him and asks if it can ask a question.'",
                                "  }",
                                "}",
                                "{",
                                "  res2: {",
                                "    text: ' Hi Jim! You just told me that your name is Jim, so I already know your name. Is there anything else I can help you with?'",
                                "  },",
                                "  memory: {",
                                "    chat_history: 'Jim introduces himself to the AI and the AI greets him and asks if it can ask a question. Jim asks what his name is and the AI responds by saying that Jim just told it his name. The AI then asks if there is anything else it can help Jim with.'",
                                "  }",
                                "}",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { PineconeClient } from \"@pinecone-database/pinecone\";\nimport * as dotenv from \"dotenv\";\nimport { Document } from \"langchain/document\";\nimport { OpenAIEmbeddings } from \"langchain/embeddings/openai\";\nimport { PineconeStore } from \"langchain/vectorstores/pinecone\";\n\ndotenv.config();\n\nconst client = new PineconeClient();\nawait client.init({\n  apiKey: process.env.PINECONE_API_KEY,\n  environment: process.env.PINECONE_ENVIRONMENT,\n});\nconst pineconeIndex = client.Index('langchain-valtown');\n\nconst docs = [\n  new Document({\n    metadata: { foo: \"bar\" },\n    pageContent: \"pinecone is a vector db\",\n  }),\n  new Document({\n    metadata: { foo: \"bar\" },\n    pageContent: \"the quick brown fox jumped over the lazy dog\",\n  }),\n  new Document({\n    metadata: { baz: \"qux\" },\n    pageContent: \"lorem ipsum dolor sit amet\",\n  }),\n  new Document({\n    metadata: { baz: \"qux\" },\n    pageContent: \"pinecones are the woody fruiting body and of a pine tree\",\n  }),\n];\n\nawait PineconeStore.fromDocuments(docs, new OpenAIEmbeddings(), {\n  pineconeIndex,\n});"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "(node:77335) Warning: Setting the NODE_TLS_REJECT_UNAUTHORIZED environment variable to '0' makes TLS connections and HTTPS requests insecure by disabling certificate verification.",
                                "(Use `node --trace-warnings ...` to show where the warning was created)",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "text/plain",
                            "value": [
                                "PineconeStore {",
                                "  embeddings: OpenAIEmbeddings {",
                                "    caller: AsyncCaller {",
                                "      maxConcurrency: \u001b[33mInfinity\u001b[39m,",
                                "      maxRetries: \u001b[33m6\u001b[39m,",
                                "      queue: \u001b[36m[PQueue]\u001b[39m",
                                "    },",
                                "    modelName: \u001b[32m'text-embedding-ada-002'\u001b[39m,",
                                "    batchSize: \u001b[33m512\u001b[39m,",
                                "    stripNewLines: \u001b[33mtrue\u001b[39m,",
                                "    timeout: \u001b[90mundefined\u001b[39m,",
                                "    azureOpenAIApiVersion: \u001b[90mundefined\u001b[39m,",
                                "    azureOpenAIApiKey: \u001b[90mundefined\u001b[39m,",
                                "    azureOpenAIApiInstanceName: \u001b[90mundefined\u001b[39m,",
                                "    azureOpenAIApiDeploymentName: \u001b[90mundefined\u001b[39m,",
                                "    azureOpenAIBasePath: \u001b[90mundefined\u001b[39m,",
                                "    client: OpenAIApi {",
                                "      basePath: \u001b[32m'https://api.openai.com/v1'\u001b[39m,",
                                "      axios: \u001b[36m[Function]\u001b[39m,",
                                "      configuration: \u001b[36m[Configuration]\u001b[39m",
                                "    },",
                                "    clientConfig: {",
                                "      apiKey: \u001b[32m'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'\u001b[39m",
                                "    }",
                                "  },",
                                "  textKey: \u001b[32m'text'\u001b[39m,",
                                "  namespace: \u001b[90mundefined\u001b[39m,",
                                "  pineconeIndex: VectorOperationsApi {",
                                "    configuration: Configuration {",
                                "      configuration: \u001b[36m[Object]\u001b[39m",
                                "    },",
                                "    fetchApi: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    middleware: [],",
                                "    _deleteRaw: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    _delete: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    delete1Raw: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    delete1: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    describeIndexStatsRaw: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    describeIndexStats: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    describeIndexStats1Raw: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    describeIndexStats1: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    fetchRaw: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    fetch: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    queryRaw: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    query: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    updateRaw: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    update: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    upsertRaw: \u001b[36m[Function (anonymous)]\u001b[39m,",
                                "    upsert: \u001b[36m[Function (anonymous)]\u001b[39m",
                                "  },",
                                "  filter: \u001b[90mundefined\u001b[39m",
                                "}"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { Milvus } from \"langchain/vectorstores/milvus\";\nimport { OpenAIEmbeddings } from \"langchain/embeddings/openai\";\n\nimport 'dotenv/config';\n\n// text sample from Godel, Escher, Bach\nconst vectorStore = await Milvus.fromTexts(\n  [\n    \"Tortoise: Labyrinth? Labyrinth? Could it Are we in the notorious Little\\\n            Harmonic Labyrinth of the dreaded Majotaur?\",\n    \"Achilles: Yiikes! What is that?\",\n    \"Tortoise: They say-although I person never believed it myself-that an I\\\n            Majotaur has created a tiny labyrinth sits in a pit in the middle of\\\n            it, waiting innocent victims to get lost in its fears complexity.\\\n            Then, when they wander and dazed into the center, he laughs and\\\n            laughs at them-so hard, that he laughs them to death!\",\n    \"Achilles: Oh, no!\",\n    \"Tortoise: But it's only a myth. Courage, Achilles.\",\n  ],\n  [{ id: 2 }, { id: 1 }, { id: 3 }, { id: 4 }, { id: 5 }],\n  new OpenAIEmbeddings(),\n  {\n    collectionName: \"langchain_valtown\",\n    clientConfig: {\n      address: process.env.ZILIZ_URL,\n      token: process.env.ZILIZ_API_KEY,\n    },\n  }\n);\n\nawait vectorStore.similaritySearch(\"scared\", 2);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "(node:65747) Warning: Setting the NODE_TLS_REJECT_UNAUTHORIZED environment variable to '0' makes TLS connections and HTTPS requests insecure by disabling certificate verification.",
                                "(Use `node --trace-warnings ...` to show where the warning was created)",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "text/plain",
                            "value": [
                                "[",
                                "  Document {",
                                "    pageContent: \u001b[32m'Achilles: Oh, no!'\u001b[39m,",
                                "    metadata: {",
                                "      id: \u001b[33m443476344924058300\u001b[39m",
                                "    }",
                                "  },",
                                "  Document {",
                                "    pageContent: \u001b[32m'Achilles: Oh, no!'\u001b[39m,",
                                "    metadata: {",
                                "      id: \u001b[33m443476344924058400\u001b[39m",
                                "    }",
                                "  }",
                                "]"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { MilvusClient, ConsistencyLevelEnum } from \"@zilliz/milvus2-sdk-node\";\n\n// connecting\nconsole.info(`Connecting to DB: ${process.env.ZILIZ_URL}`);\nconst client = new MilvusClient({ \n  address: process.env.ZILIZ_URL!, \n  token: process.env.ZILIZ_API_KEY, \n});\nconsole.info(`Success!`);\n\n(async () => {\n  // dimension\n  const dimension = 64;\n  const collection_name = \"hello_milvus\";\n  const num_of_rows = 1000;\n  // create colleciton\n  console.time(`Creating example collection: ${collection_name}`);\n  await client.createCollection({\n    collection_name,\n    dimension,\n  });\n  console.timeEnd(`Creating example collection: ${collection_name}`);\n\n  const data = [];\n  Array(num_of_rows)\n    .fill(1)\n    .forEach(() => {\n      data.push({\n        id: Math.floor(Math.random() * 100000),\n        vector: [...Array(dimension)].map(() => Math.random()),\n      });\n    });\n  // inserting\n  console.time(`Inserting 1000 entities successfully`);\n  await client.insert({\n    collection_name,\n    data,\n  });\n  console.timeEnd(`Inserting 1000 entities successfully`);\n\n  // search\n  console.time(`Searching vector`);\n  const res = await client.search({\n    collection_name,\n    vector: data[0][\"vector\"],\n    output_fields: [\"id\"],\n    limit: 10,\n    consistency_level: ConsistencyLevelEnum.Bounded,\n  });\n  console.timeEnd(`Searching vector`);\n  console.log(res);\n})();\n"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "Connecting to DB: https://in01-a7a3b0886b68e94.aws-ap-southeast-1.vectordb.zillizcloud.com:19531",
                                "Success!",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "(node:60330) Warning: Label 'Creating example collection: hello_milvus' already exists for console.time()",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "// import\nimport * as hub from \"langchain/hub\";\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\n\nimport 'dotenv/config';\n\n// pull a chat prompt\nconst prompt = await hub.pull(\"zhanghaili/test\");\nconsole.log(prompt);\n\n// create a model to use it with\nconst model = new ChatOpenAI();\n\n// use it in a runnable\nconst runnable = prompt.pipe(model);\nconst result = await runnable.invoke({\n\t// \"input_language\": \"English\",\n\t// \"output_language\": \"Chinese\",\n\t// \"text\": \"Parrots sometimes squawk and sometimes speak\",\n\tinput: 'hello',\n});\n\nconsole.log(result);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "PromptTemplate {",
                                "  lc_serializable: true,",
                                "  lc_kwargs: {",
                                "    template: 'You are a parrot. The current date is 2023-08-27T10:03:36.286Z\\n{input}',",
                                "    inputVariables: [ 'input' ],",
                                "    templateFormat: 'f-string'",
                                "  },",
                                "  lc_runnable: true,",
                                "  lc_namespace: [ 'langchain', 'prompts', 'prompt' ],",
                                "  inputVariables: [ 'input' ],",
                                "  outputParser: undefined,",
                                "  partialVariables: undefined,",
                                "  template: 'You are a parrot. The current date is 2023-08-27T10:03:36.286Z\\n{input}',",
                                "  templateFormat: 'f-string',",
                                "  validateTemplate: true",
                                "}",
                                "AIMessage {",
                                "  lc_serializable: true,",
                                "  lc_kwargs: {",
                                "    content: \"Hello! Squawk! I'm just a parrot, but I'm here to chat with you! How can I assist you today? Squawk!\",",
                                "    additional_kwargs: { function_call: undefined }",
                                "  },",
                                "  lc_namespace: [ 'langchain', 'schema' ],",
                                "  content: \"Hello! Squawk! I'm just a parrot, but I'm here to chat with you! How can I assist you today? Squawk!\",",
                                "  name: undefined,",
                                "  additional_kwargs: { function_call: undefined }",
                                "}",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import * as hub from \"langchain/hub\";\nimport { PromptTemplate } from \"langchain/prompts\";\n\nimport 'dotenv/config';\n\nconst prompt = PromptTemplate.fromTemplate(\n  `You are a parrot. The current date is ${new Date().toISOString()}\\n{input}`\n);\n\nawait hub.push('zhanghaili/test', prompt);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "(node:46004) Warning: Setting the NODE_TLS_REJECT_UNAUTHORIZED environment variable to '0' makes TLS connections and HTTPS requests insecure by disabling certificate verification.",
                                "(Use `node --trace-warnings ...` to show where the warning was created)",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "text/plain",
                            "value": [
                                "{",
                                "  commit: {",
                                "    id: \u001b[32m'a4ee71a4-5855-446d-8a30-df4a29afd230'\u001b[39m,",
                                "    manifest_id: \u001b[32m'89cdc1bf-3d47-4d4b-92b2-de946bf7ecd5'\u001b[39m,",
                                "    repo_id: \u001b[32m'eb33e371-c3f5-4a5d-ba13-5b1601302dea'\u001b[39m,",
                                "    parent_id: \u001b[32m'0e29d9a2-86b5-4315-bb0e-83ce822aa3fb'\u001b[39m,",
                                "    commit_hash: \u001b[32m'a835b9d007139ff79c1c2d4c37e18a20562bc8664cef8edfd0cc192dce0ce098'\u001b[39m,",
                                "    created_at: \u001b[32m'2023-08-27T10:03:43.503113'\u001b[39m,",
                                "    updated_at: \u001b[32m'2023-08-27T10:03:43.503113'\u001b[39m,",
                                "    num_downloads: \u001b[33m0\u001b[39m,",
                                "    parent_commit_hash: \u001b[32m'19db7d1453057d03b1124936b9c455eee5b6595e5daed8a077c5969e6ff0af6f'\u001b[39m",
                                "  }",
                                "}"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { z } from \"zod\";\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport { initializeAgentExecutorWithOptions } from \"langchain/agents\";\nimport { Calculator } from \"langchain/tools/calculator\";\nimport { DynamicStructuredTool } from \"langchain/tools\";\n\nimport 'dotenv/config';\n\n\nconst model = new ChatOpenAI({ temperature: 0 });\nconst tools = [\n  new Calculator(), // Older existing single input tools will still work\n  new DynamicStructuredTool({\n    name: \"random-number-generator\",\n    description: \"generates a random number between two input numbers\",\n    schema: z.object({\n      low: z.number().describe(\"The lower bound of the generated number\"),\n      high: z.number().describe(\"The upper bound of the generated number\"),\n    }),\n    func: async ({ low, high }) =>\n      (Math.random() * (high - low) + low).toString(), // Outputs still must be strings\n    returnDirect: false, // This is an option that allows the tool to return the output directly\n  }),\n];\n\nconst executor = await initializeAgentExecutorWithOptions(tools, model, {\n  agentType: \"structured-chat-zero-shot-react-description\",\n  verbose: true,\n});\nconsole.log(\"Loaded agent.\");\n\nconst input = `What is a random number between 5 and 10 raised to the second power?`;\n\nconsole.log(`Executing with input \"${input}\"...`);\n\nconst result = await executor.call({ input });\n\nconsole.log({ result });\n"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "Loaded agent.",
                                "Executing with input \"What is a random number between 5 and 10 raised to the second power?\"...",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:AgentExecutor\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"What is a random number between 5 and 10 raised to the second power?\"",
                                "}",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m2:chain:LLMChain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"What is a random number between 5 and 10 raised to the second power?\",",
                                "  \"agent_scratchpad\": \"\",",
                                "  \"stop\": [",
                                "    \"Observation:\"",
                                "  ]",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:LLMChain > \u001b[1m3:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Answer the following questions truthfully and as best you can.\\n\\nYou have access to the following tools.\\nYou must format your inputs to these tools to match their \\\"JSON schema\\\" definitions below.\\n\\n\\\"JSON Schema\\\" is a declarative language that allows you to annotate and validate JSON documents.\\n\\nFor example, the example \\\"JSON Schema\\\" instance {\\\"properties\\\": {\\\"foo\\\": {\\\"description\\\": \\\"a list of test words\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]}}\\nwould match an object with one required property, \\\"foo\\\". The \\\"type\\\" property specifies \\\"foo\\\" must be an \\\"array\\\", and the \\\"description\\\" property semantically describes it as \\\"a list of test words\\\". The items within \\\"foo\\\" must be strings.\\nThus, the object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of this example \\\"JSON Schema\\\". The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere are the JSON Schema instances for the tools you have access to:\\n\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator., args: {\\\"input\\\":{\\\"type\\\":\\\"string\\\"}}\\nrandom-number-generator: generates a random number between two input numbers, args: {\\\"low\\\":{\\\"type\\\":\\\"number\\\",\\\"description\\\":\\\"The lower bound of the generated number\\\"},\\\"high\\\":{\\\"type\\\":\\\"number\\\",\\\"description\\\":\\\"The upper bound of the generated number\\\"}}\\n\\nThe way you use the tools is as follows:\\n\\n------------------------\\n\\nOutput a JSON markdown code snippet containing a valid JSON blob (denoted below by $JSON_BLOB).\\nThis $JSON_BLOB must have a \\\"action\\\" key (with the name of the tool to use) and an \\\"action_input\\\" key (tool input).\\n\\nValid \\\"action\\\" values: \\\"Final Answer\\\" (which you must use when giving your final response to the user), or one of [calculator, random-number-generator].\\n\\nThe $JSON_BLOB must be valid, parseable JSON and only contain a SINGLE action. Here is an example of an acceptable output:\\n\\n```json\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nRemember to include the surrounding markdown code snippet delimiters (begin with \\\"```\\\" json and close with \\\"```\\\")!\\n\\n\\nIf you are using a tool, \\\"action_input\\\" must adhere to the tool's input schema, given above.\\n\\n------------------------\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```json\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nAction:\\n```json\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Final response to human\\\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS use the above format, and to use tools if appropriate.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"What is a random number between 5 and 10 raised to the second power?\\n\\n\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:LLMChain > \u001b[1m3:llm:ChatOpenAI\u001b[22m\u001b[39m] [4.05s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"I can use the random-number-generator tool to generate a random number between 5 and 10. Then I can use the calculator tool to raise that number to the second power.\\n\\nAction:\\n```json\\n{\\n  \\\"action\\\": \\\"random-number-generator\\\",\\n  \\\"action_input\\\": {\\n    \\\"low\\\": 5,\\n    \\\"high\\\": 10\\n  }\\n}\\n```\\n\\n\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"I can use the random-number-generator tool to generate a random number between 5 and 10. Then I can use the calculator tool to raise that number to the second power.\\n\\nAction:\\n```json\\n{\\n  \\\"action\\\": \\\"random-number-generator\\\",\\n  \\\"action_input\\\": {\\n    \\\"low\\\": 5,\\n    \\\"high\\\": 10\\n  }\\n}\\n```\\n\\n\",",
                                "            \"additional_kwargs\": {}",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"stop\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 76,",
                                "      \"promptTokens\": 657,",
                                "      \"totalTokens\": 733",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m2:chain:LLMChain\u001b[22m\u001b[39m] [4.74s] Exiting Chain run with output: {",
                                "  \"text\": \"I can use the random-number-generator tool to generate a random number between 5 and 10. Then I can use the calculator tool to raise that number to the second power.\\n\\nAction:\\n```json\\n{\\n  \\\"action\\\": \\\"random-number-generator\\\",\\n  \\\"action_input\\\": {\\n    \\\"low\\\": 5,\\n    \\\"high\\\": 10\\n  }\\n}\\n```\\n\\n\"",
                                "}",
                                "\u001b[36m[tool/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m4:tool:DynamicStructuredTool\u001b[22m\u001b[39m] [249ms] Exiting Tool run with output: \"5.10414753513435\"",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 5:chain:LLMChain > \u001b[1m6:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Answer the following questions truthfully and as best you can.\\n\\nYou have access to the following tools.\\nYou must format your inputs to these tools to match their \\\"JSON schema\\\" definitions below.\\n\\n\\\"JSON Schema\\\" is a declarative language that allows you to annotate and validate JSON documents.\\n\\nFor example, the example \\\"JSON Schema\\\" instance {\\\"properties\\\": {\\\"foo\\\": {\\\"description\\\": \\\"a list of test words\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]}}\\nwould match an object with one required property, \\\"foo\\\". The \\\"type\\\" property specifies \\\"foo\\\" must be an \\\"array\\\", and the \\\"description\\\" property semantically describes it as \\\"a list of test words\\\". The items within \\\"foo\\\" must be strings.\\nThus, the object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of this example \\\"JSON Schema\\\". The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere are the JSON Schema instances for the tools you have access to:\\n\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator., args: {\\\"input\\\":{\\\"type\\\":\\\"string\\\"}}\\nrandom-number-generator: generates a random number between two input numbers, args: {\\\"low\\\":{\\\"type\\\":\\\"number\\\",\\\"description\\\":\\\"The lower bound of the generated number\\\"},\\\"high\\\":{\\\"type\\\":\\\"number\\\",\\\"description\\\":\\\"The upper bound of the generated number\\\"}}\\n\\nThe way you use the tools is as follows:\\n\\n------------------------\\n\\nOutput a JSON markdown code snippet containing a valid JSON blob (denoted below by $JSON_BLOB).\\nThis $JSON_BLOB must have a \\\"action\\\" key (with the name of the tool to use) and an \\\"action_input\\\" key (tool input).\\n\\nValid \\\"action\\\" values: \\\"Final Answer\\\" (which you must use when giving your final response to the user), or one of [calculator, random-number-generator].\\n\\nThe $JSON_BLOB must be valid, parseable JSON and only contain a SINGLE action. Here is an example of an acceptable output:\\n\\n```json\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nRemember to include the surrounding markdown code snippet delimiters (begin with \\\"```\\\" json and close with \\\"```\\\")!\\n\\n\\nIf you are using a tool, \\\"action_input\\\" must adhere to the tool's input schema, given above.\\n\\n------------------------\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```json\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nAction:\\n```json\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Final response to human\\\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS use the above format, and to use tools if appropriate.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"What is a random number between 5 and 10 raised to the second power?\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nI can use the random-number-generator tool to generate a random number between 5 and 10. Then I can use the calculator tool to raise that number to the second power.\\n\\nAction:\\n```json\\n{\\n  \\\"action\\\": \\\"random-number-generator\\\",\\n  \\\"action_input\\\": {\\n    \\\"low\\\": 5,\\n    \\\"high\\\": 10\\n  }\\n}\\n```\\n\\n\\nObservation: 5.10414753513435\\nThought:\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 5:chain:LLMChain > \u001b[1m6:llm:ChatOpenAI\u001b[22m\u001b[39m] [3.64s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"Now I have a random number between 5 and 10. I can use the calculator tool to raise that number to the second power.\\n\\nAction:\\n```json\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"5.10414753513435^2\\\"\\n}\\n```\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"Now I have a random number between 5 and 10. I can use the calculator tool to raise that number to the second power.\\n\\nAction:\\n```json\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"5.10414753513435^2\\\"\\n}\\n```\",",
                                "            \"additional_kwargs\": {}",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"stop\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 59,",
                                "      \"promptTokens\": 772,",
                                "      \"totalTokens\": 831",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[32m[tool/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m7:tool:Calculator\u001b[22m\u001b[39m] Entering Tool run with input: \"5.10414753513435^2\"",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m8:chain:LLMChain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"What is a random number between 5 and 10 raised to the second power?\",",
                                "  \"agent_scratchpad\": \"This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nI can use the random-number-generator tool to generate a random number between 5 and 10. Then I can use the calculator tool to raise that number to the second power.\\n\\nAction:\\n```json\\n{\\n  \\\"action\\\": \\\"random-number-generator\\\",\\n  \\\"action_input\\\": {\\n    \\\"low\\\": 5,\\n    \\\"high\\\": 10\\n  }\\n}\\n```\\n\\n\\nObservation: 5.10414753513435\\nThought:Now I have a random number between 5 and 10. I can use the calculator tool to raise that number to the second power.\\n\\nAction:\\n```json\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"5.10414753513435^2\\\"\\n}\\n```\\nObservation: 26.052322060418064\\nThought:\",",
                                "  \"stop\": [",
                                "    \"Observation:\"",
                                "  ]",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 8:chain:LLMChain > \u001b[1m9:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Answer the following questions truthfully and as best you can.\\n\\nYou have access to the following tools.\\nYou must format your inputs to these tools to match their \\\"JSON schema\\\" definitions below.\\n\\n\\\"JSON Schema\\\" is a declarative language that allows you to annotate and validate JSON documents.\\n\\nFor example, the example \\\"JSON Schema\\\" instance {\\\"properties\\\": {\\\"foo\\\": {\\\"description\\\": \\\"a list of test words\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]}}\\nwould match an object with one required property, \\\"foo\\\". The \\\"type\\\" property specifies \\\"foo\\\" must be an \\\"array\\\", and the \\\"description\\\" property semantically describes it as \\\"a list of test words\\\". The items within \\\"foo\\\" must be strings.\\nThus, the object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of this example \\\"JSON Schema\\\". The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere are the JSON Schema instances for the tools you have access to:\\n\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator., args: {\\\"input\\\":{\\\"type\\\":\\\"string\\\"}}\\nrandom-number-generator: generates a random number between two input numbers, args: {\\\"low\\\":{\\\"type\\\":\\\"number\\\",\\\"description\\\":\\\"The lower bound of the generated number\\\"},\\\"high\\\":{\\\"type\\\":\\\"number\\\",\\\"description\\\":\\\"The upper bound of the generated number\\\"}}\\n\\nThe way you use the tools is as follows:\\n\\n------------------------\\n\\nOutput a JSON markdown code snippet containing a valid JSON blob (denoted below by $JSON_BLOB).\\nThis $JSON_BLOB must have a \\\"action\\\" key (with the name of the tool to use) and an \\\"action_input\\\" key (tool input).\\n\\nValid \\\"action\\\" values: \\\"Final Answer\\\" (which you must use when giving your final response to the user), or one of [calculator, random-number-generator].\\n\\nThe $JSON_BLOB must be valid, parseable JSON and only contain a SINGLE action. Here is an example of an acceptable output:\\n\\n```json\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nRemember to include the surrounding markdown code snippet delimiters (begin with \\\"```\\\" json and close with \\\"```\\\")!\\n\\n\\nIf you are using a tool, \\\"action_input\\\" must adhere to the tool's input schema, given above.\\n\\n------------------------\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```json\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nAction:\\n```json\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Final response to human\\\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS use the above format, and to use tools if appropriate.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"What is a random number between 5 and 10 raised to the second power?\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nI can use the random-number-generator tool to generate a random number between 5 and 10. Then I can use the calculator tool to raise that number to the second power.\\n\\nAction:\\n```json\\n{\\n  \\\"action\\\": \\\"random-number-generator\\\",\\n  \\\"action_input\\\": {\\n    \\\"low\\\": 5,\\n    \\\"high\\\": 10\\n  }\\n}\\n```\\n\\n\\nObservation: 5.10414753513435\\nThought:Now I have a random number between 5 and 10. I can use the calculator tool to raise that number to the second power.\\n\\nAction:\\n```json\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"5.10414753513435^2\\\"\\n}\\n```\\nObservation: 26.052322060418064\\nThought:\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 8:chain:LLMChain > \u001b[1m9:llm:ChatOpenAI\u001b[22m\u001b[39m] [4.16s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"Now I have the result of raising the random number between 5 and 10 to the second power. I can provide the final answer to the user.\\n\\nAction:\\n```json\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"The random number between 5 and 10 raised to the second power is 26.052322060418064.\\\"\\n}\\n```\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"Now I have the result of raising the random number between 5 and 10 to the second power. I can provide the final answer to the user.\\n\\nAction:\\n```json\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"The random number between 5 and 10 raised to the second power is 26.052322060418064.\\\"\\n}\\n```\",",
                                "            \"additional_kwargs\": {}",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"stop\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 77,",
                                "      \"promptTokens\": 846,",
                                "      \"totalTokens\": 923",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:AgentExecutor\u001b[22m\u001b[39m] [15.82s] Exiting Chain run with output: {",
                                "  \"output\": \"The random number between 5 and 10 raised to the second power is 26.052322060418064.\"",
                                "}",
                                "{",
                                "  result: {",
                                "    output: 'The random number between 5 and 10 raised to the second power is 26.052322060418064.'",
                                "  }",
                                "}",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport { ConversationalRetrievalQAChain } from \"langchain/chains\";\nimport { HNSWLib } from \"langchain/vectorstores/hnswlib\";\nimport { OpenAIEmbeddings } from \"langchain/embeddings/openai\";\nimport { BufferMemory } from \"langchain/memory\";\n\nconst CUSTOM_QUESTION_GENERATOR_CHAIN_PROMPT = `Given the following conversation and a follow up question, return the conversation history excerpt that includes any relevant context to the question if it exists and rephrase the follow up question to be a standalone question.\nChat History:\n{chat_history}\nFollow Up Input: {question}\nYour answer should follow the following format:\n\\`\\`\\`\nUse the following pieces of context to answer the users question.\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\n----------------\n<Relevant chat history excerpt as context here>\nStandalone question: <Rephrased question here>\n\\`\\`\\`\nYour answer:`;\n\nconst model = new ChatOpenAI({\n  modelName: \"gpt-3.5-turbo\",\n  temperature: 0,\n});\n\nconst vectorStore = await HNSWLib.fromTexts(\n  [\n    \"Mitochondria are the powerhouse of the cell\",\n    \"Foo is red\",\n    \"Bar is red\",\n    \"Buildings are made out of brick\",\n    \"Mitochondria are made of lipids\",\n  ],\n  [{ id: 2 }, { id: 1 }, { id: 3 }, { id: 4 }, { id: 5 }],\n  new OpenAIEmbeddings()\n);\n\nconst chain = ConversationalRetrievalQAChain.fromLLM(\n  model,\n  vectorStore.asRetriever(),\n  {\n    memory: new BufferMemory({\n      memoryKey: \"chat_history\",\n      returnMessages: true,\n    }),\n    questionGeneratorChainOptions: {\n      template: CUSTOM_QUESTION_GENERATOR_CHAIN_PROMPT,\n    },\n  }\n);\n\nconst res = await chain.call({\n  question:\n    \"I have a friend called Bob. He's 28 years old. He'd like to know what the powerhouse of the cell is?\",\n});\n\nconsole.log(res);\n/*\n  {\n    text: \"The powerhouse of the cell is the mitochondria.\"\n  }\n*/\n\nconst res2 = await chain.call({\n  question: \"How old is Bob?\",\n});\n\nconsole.log(res2); // Bob is 28 years old.\n\n/*\n  {\n    text: \"Bob is 28 years old.\"\n  }\n*/"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "(node:2789) Warning: Setting the NODE_TLS_REJECT_UNAUTHORIZED environment variable to '0' makes TLS connections and HTTPS requests insecure by disabling certificate verification.",
                                "(Use `node --trace-warnings ...` to show where the warning was created)",
                                "{ text: \"Bob's age is 28 years old.\" }",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "{ text: 'The powerhouse of the cell is the mitochondria.' }",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { SequentialChain, LLMChain } from \"langchain/chains\";\nimport { OpenAI } from \"langchain/llms/openai\";\nimport { PromptTemplate } from \"langchain/prompts\";\n\n// This is an LLMChain to write a synopsis given a title of a play and the era it is set in.\nconst llm = new OpenAI({ temperature: 0 });\nconst template = `You are a playwright. Given the title of play and the era it is set in, it is your job to write a synopsis for that title.\n\nTitle: {title}\nEra: {era}\nPlaywright: This is a synopsis for the above play:`;\nconst promptTemplate = new PromptTemplate({\n  template,\n  inputVariables: [\"title\", \"era\"],\n});\nconst synopsisChain = new LLMChain({\n  llm,\n  prompt: promptTemplate,\n  outputKey: \"synopsis\",\n});\n\n// This is an LLMChain to write a review of a play given a synopsis.\nconst reviewLLM = new OpenAI({ temperature: 0 });\nconst reviewTemplate = `You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n  \n   Play Synopsis:\n   {synopsis}\n   Review from a New York Times play critic of the above play:`;\nconst reviewPromptTemplate = new PromptTemplate({\n  template: reviewTemplate,\n  inputVariables: [\"synopsis\"],\n});\nconst reviewChain = new LLMChain({\n  llm: reviewLLM,\n  prompt: reviewPromptTemplate,\n  outputKey: \"review\",\n});\n\nconst overallChain = new SequentialChain({\n  chains: [synopsisChain, reviewChain],\n  inputVariables: [\"era\", \"title\"],\n  // Here we return multiple variables\n  outputVariables: [\"synopsis\", \"review\"],\n  verbose: true,\n});\nconst chainExecutionResult = await overallChain.call({\n  title: \"Tragedy at sunset on the beach\",\n  era: \"Victorian England\",\n});\nconsole.log(chainExecutionResult);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:SequentialChain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"title\": \"Tragedy at sunset on the beach\",",
                                "  \"era\": \"Victorian England\"",
                                "}",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:SequentialChain > \u001b[1m2:chain:LLMChain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"title\": \"Tragedy at sunset on the beach\",",
                                "  \"era\": \"Victorian England\"",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:SequentialChain > 2:chain:LLMChain > \u001b[1m3:llm:OpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"You are a playwright. Given the title of play and the era it is set in, it is your job to write a synopsis for that title.\\n\\nTitle: Tragedy at sunset on the beach\\nEra: Victorian England\\nPlaywright: This is a synopsis for the above play:\"",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:SequentialChain > 2:chain:LLMChain > \u001b[1m3:llm:OpenAI\u001b[22m\u001b[39m] [3.93s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"\\n\\nTragedy at Sunset on the Beach is a play set in Victorian England. It tells the story of a young woman, Emily, who is struggling to make ends meet in a small coastal town. She works as a maid for a wealthy family, but her dreams of a better life are dashed when she discovers that her employer is involved in a scandalous affair.\\n\\nEmily is determined to make a better life for herself, but her plans are thwarted when she meets a handsome stranger on the beach one evening. The two quickly fall in love, but their happiness is short-lived when Emily discovers that the stranger is actually a member of the wealthy family she works for.\\n\\nThe play follows Emily as she struggles to come to terms with the truth and make sense of her life. As the sun sets on the beach, Emily must decide whether to stay with the man she loves or to leave him and pursue her dreams. In the end, Emily must make a heartbreaking decision that will change her life forever.\",",
                                "        \"generationInfo\": {",
                                "          \"finishReason\": \"stop\",",
                                "          \"logprobs\": null",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 205,",
                                "      \"promptTokens\": 62,",
                                "      \"totalTokens\": 267",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:SequentialChain > \u001b[1m2:chain:LLMChain\u001b[22m\u001b[39m] [4.46s] Exiting Chain run with output: {",
                                "  \"synopsis\": \"\\n\\nTragedy at Sunset on the Beach is a play set in Victorian England. It tells the story of a young woman, Emily, who is struggling to make ends meet in a small coastal town. She works as a maid for a wealthy family, but her dreams of a better life are dashed when she discovers that her employer is involved in a scandalous affair.\\n\\nEmily is determined to make a better life for herself, but her plans are thwarted when she meets a handsome stranger on the beach one evening. The two quickly fall in love, but their happiness is short-lived when Emily discovers that the stranger is actually a member of the wealthy family she works for.\\n\\nThe play follows Emily as she struggles to come to terms with the truth and make sense of her life. As the sun sets on the beach, Emily must decide whether to stay with the man she loves or to leave him and pursue her dreams. In the end, Emily must make a heartbreaking decision that will change her life forever.\"",
                                "}",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:SequentialChain > \u001b[1m4:chain:LLMChain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"title\": \"Tragedy at sunset on the beach\",",
                                "  \"era\": \"Victorian England\",",
                                "  \"synopsis\": \"\\n\\nTragedy at Sunset on the Beach is a play set in Victorian England. It tells the story of a young woman, Emily, who is struggling to make ends meet in a small coastal town. She works as a maid for a wealthy family, but her dreams of a better life are dashed when she discovers that her employer is involved in a scandalous affair.\\n\\nEmily is determined to make a better life for herself, but her plans are thwarted when she meets a handsome stranger on the beach one evening. The two quickly fall in love, but their happiness is short-lived when Emily discovers that the stranger is actually a member of the wealthy family she works for.\\n\\nThe play follows Emily as she struggles to come to terms with the truth and make sense of her life. As the sun sets on the beach, Emily must decide whether to stay with the man she loves or to leave him and pursue her dreams. In the end, Emily must make a heartbreaking decision that will change her life forever.\"",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:SequentialChain > 4:chain:LLMChain > \u001b[1m5:llm:OpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\\n  \\n   Play Synopsis:\\n   \\n\\nTragedy at Sunset on the Beach is a play set in Victorian England. It tells the story of a young woman, Emily, who is struggling to make ends meet in a small coastal town. She works as a maid for a wealthy family, but her dreams of a better life are dashed when she discovers that her employer is involved in a scandalous affair.\\n\\nEmily is determined to make a better life for herself, but her plans are thwarted when she meets a handsome stranger on the beach one evening. The two quickly fall in love, but their happiness is short-lived when Emily discovers that the stranger is actually a member of the wealthy family she works for.\\n\\nThe play follows Emily as she struggles to come to terms with the truth and make sense of her life. As the sun sets on the beach, Emily must decide whether to stay with the man she loves or to leave him and pursue her dreams. In the end, Emily must make a heartbreaking decision that will change her life forever.\\n   Review from a New York Times play critic of the above play:\"",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:SequentialChain > 4:chain:LLMChain > \u001b[1m5:llm:OpenAI\u001b[22m\u001b[39m] [3.26s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"\\n\\nTragedy at Sunset on the Beach is a captivating and heartbreaking story of love and loss. Set in Victorian England, the play follows Emily, a young woman struggling to make ends meet in a small coastal town. Emily's dreams of a better life are dashed when she discovers her employer is involved in a scandalous affair, and her plans are further thwarted when she meets a handsome stranger on the beach.\\n\\nThe play is a powerful exploration of the human condition, as Emily must grapple with the truth and make a difficult decision that will change her life forever. The performances are outstanding, with the actors bringing a depth of emotion to their characters that is both heartbreaking and inspiring.\\n\\nOverall, Tragedy at Sunset on the Beach is a powerful and moving play that will leave audiences in tears. It is a must-see for anyone looking for a thought-provoking and emotionally charged experience.\",",
                                "        \"generationInfo\": {",
                                "          \"finishReason\": \"stop\",",
                                "          \"logprobs\": null",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 184,",
                                "      \"promptTokens\": 259,",
                                "      \"totalTokens\": 443",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:SequentialChain > \u001b[1m4:chain:LLMChain\u001b[22m\u001b[39m] [3.75s] Exiting Chain run with output: {",
                                "  \"review\": \"\\n\\nTragedy at Sunset on the Beach is a captivating and heartbreaking story of love and loss. Set in Victorian England, the play follows Emily, a young woman struggling to make ends meet in a small coastal town. Emily's dreams of a better life are dashed when she discovers her employer is involved in a scandalous affair, and her plans are further thwarted when she meets a handsome stranger on the beach.\\n\\nThe play is a powerful exploration of the human condition, as Emily must grapple with the truth and make a difficult decision that will change her life forever. The performances are outstanding, with the actors bringing a depth of emotion to their characters that is both heartbreaking and inspiring.\\n\\nOverall, Tragedy at Sunset on the Beach is a powerful and moving play that will leave audiences in tears. It is a must-see for anyone looking for a thought-provoking and emotionally charged experience.\"",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:SequentialChain\u001b[22m\u001b[39m] [9.00s] Exiting Chain run with output: {",
                                "  \"synopsis\": \"\\n\\nTragedy at Sunset on the Beach is a play set in Victorian England. It tells the story of a young woman, Emily, who is struggling to make ends meet in a small coastal town. She works as a maid for a wealthy family, but her dreams of a better life are dashed when she discovers that her employer is involved in a scandalous affair.\\n\\nEmily is determined to make a better life for herself, but her plans are thwarted when she meets a handsome stranger on the beach one evening. The two quickly fall in love, but their happiness is short-lived when Emily discovers that the stranger is actually a member of the wealthy family she works for.\\n\\nThe play follows Emily as she struggles to come to terms with the truth and make sense of her life. As the sun sets on the beach, Emily must decide whether to stay with the man she loves or to leave him and pursue her dreams. In the end, Emily must make a heartbreaking decision that will change her life forever.\",",
                                "  \"review\": \"\\n\\nTragedy at Sunset on the Beach is a captivating and heartbreaking story of love and loss. Set in Victorian England, the play follows Emily, a young woman struggling to make ends meet in a small coastal town. Emily's dreams of a better life are dashed when she discovers her employer is involved in a scandalous affair, and her plans are further thwarted when she meets a handsome stranger on the beach.\\n\\nThe play is a powerful exploration of the human condition, as Emily must grapple with the truth and make a difficult decision that will change her life forever. The performances are outstanding, with the actors bringing a depth of emotion to their characters that is both heartbreaking and inspiring.\\n\\nOverall, Tragedy at Sunset on the Beach is a powerful and moving play that will leave audiences in tears. It is a must-see for anyone looking for a thought-provoking and emotionally charged experience.\"",
                                "}",
                                "{",
                                "  synopsis: '\\n' +",
                                "    '\\n' +",
                                "    'Tragedy at Sunset on the Beach is a play set in Victorian England. It tells the story of a young woman, Emily, who is struggling to make ends meet in a small coastal town. She works as a maid for a wealthy family, but her dreams of a better life are dashed when she discovers that her employer is involved in a scandalous affair.\\n' +",
                                "    '\\n' +",
                                "    'Emily is determined to make a better life for herself, but her plans are thwarted when she meets a handsome stranger on the beach one evening. The two quickly fall in love, but their happiness is short-lived when Emily discovers that the stranger is actually a member of the wealthy family she works for.\\n' +",
                                "    '\\n' +",
                                "    'The play follows Emily as she struggles to come to terms with the truth and make sense of her life. As the sun sets on the beach, Emily must decide whether to stay with the man she loves or to leave him and pursue her dreams. In the end, Emily must make a heartbreaking decision that will change her life forever.',",
                                "  review: '\\n' +",
                                "    '\\n' +",
                                "    \"Tragedy at Sunset on the Beach is a captivating and heartbreaking story of love and loss. Set in Victorian England, the play follows Emily, a young woman struggling to make ends meet in a small coastal town. Emily's dreams of a better life are dashed when she discovers her employer is involved in a scandalous affair, and her plans are further thwarted when she meets a handsome stranger on the beach.\\n\" +",
                                "    '\\n' +",
                                "    'The play is a powerful exploration of the human condition, as Emily must grapple with the truth and make a difficult decision that will change her life forever. The performances are outstanding, with the actors bringing a depth of emotion to their characters that is both heartbreaking and inspiring.\\n' +",
                                "    '\\n' +",
                                "    'Overall, Tragedy at Sunset on the Beach is a powerful and moving play that will leave audiences in tears. It is a must-see for anyone looking for a thought-provoking and emotionally charged experience.'",
                                "}",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { OpenAI } from \"langchain/llms/openai\";\nimport { APIChain } from \"langchain/chains\";\n\nconst OPEN_METEO_DOCS = `BASE URL: https://api.open-meteo.com/\n\nAPI Documentation\nThe API endpoint /v1/forecast accepts a geographical coordinate, a list of weather variables and responds with a JSON hourly weather forecast for 7 days. Time always starts at 0:00 today and contains 168 hours. All URL parameters are listed below:\n\nParameter\tFormat\tRequired\tDefault\tDescription\nlatitude, longitude\tFloating point\tYes\t\tGeographical WGS84 coordinate of the location\nhourly\tString array\tNo\t\tA list of weather variables which should be returned. Values can be comma separated, or multiple &hourly= parameter in the URL can be used.\ndaily\tString array\tNo\t\tA list of daily weather variable aggregations which should be returned. Values can be comma separated, or multiple &daily= parameter in the URL can be used. If daily weather variables are specified, parameter timezone is required.\ncurrent_weather\tBool\tNo\tfalse\tInclude current weather conditions in the JSON output.\ntemperature_unit\tString\tNo\tcelsius\tIf fahrenheit is set, all temperature values are converted to Fahrenheit.\nwindspeed_unit\tString\tNo\tkmh\tOther wind speed speed units: ms, mph and kn\nprecipitation_unit\tString\tNo\tmm\tOther precipitation amount units: inch\ntimeformat\tString\tNo\tiso8601\tIf format unixtime is selected, all time values are returned in UNIX epoch time in seconds. Please note that all timestamp are in GMT+0! For daily values with unix timestamps, please apply utc_offset_seconds again to get the correct date.\ntimezone\tString\tNo\tGMT\tIf timezone is set, all timestamps are returned as local-time and data is returned starting at 00:00 local-time. Any time zone name from the time zone database is supported. If auto is set as a time zone, the coordinates will be automatically resolved to the local time zone.\npast_days\tInteger (0-2)\tNo\t0\tIf past_days is set, yesterday or the day before yesterday data are also returned.\nstart_date\nend_date\tString (yyyy-mm-dd)\tNo\t\tThe time interval to get weather data. A day must be specified as an ISO8601 date (e.g. 2022-06-30).\nmodels\tString array\tNo\tauto\tManually select one or more weather models. Per default, the best suitable weather models will be combined.\n\nVariable\tValid time\tUnit\tDescription\ntemperature_2m\tInstant\t°C (°F)\tAir temperature at 2 meters above ground\nsnowfall\tPreceding hour sum\tcm (inch)\tSnowfall amount of the preceding hour in centimeters. For the water equivalent in millimeter, divide by 7. E.g. 7 cm snow = 10 mm precipitation water equivalent\nrain\tPreceding hour sum\tmm (inch)\tRain from large scale weather systems of the preceding hour in millimeter\nshowers\tPreceding hour sum\tmm (inch)\tShowers from convective precipitation in millimeters from the preceding hour\nweathercode\tInstant\tWMO code\tWeather condition as a numeric code. Follow WMO weather interpretation codes. See table below for details.\nsnow_depth\tInstant\tmeters\tSnow depth on the ground\nfreezinglevel_height\tInstant\tmeters\tAltitude above sea level of the 0°C level\nvisibility\tInstant\tmeters\tViewing distance in meters. Influenced by low clouds, humidity and aerosols. Maximum visibility is approximately 24 km.`;\n\n\nconst model = new OpenAI({ modelName: \"text-davinci-003\" });\nconst chain = APIChain.fromLLMAndAPIDocs(model, OPEN_METEO_DOCS, {\n  headers: {\n    // These headers will be used for API requests made by the chain.\n  },\n});\n\nconst res = await chain.call({\n  question:\n    \"What is the weather like right now in Munich, Germany in degrees Farenheit?\",\n});\nconsole.log({ res });\n"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "{",
                                "  res: {",
                                "    output: ' The current weather in Munich, Germany is 72.5 degrees Farenheit, with a windspeed of 1.3 km/h, a winddirection of 236 degrees, a weathercode of 1, and it is currently daytime.'",
                                "  }",
                                "}",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { DataSource } from \"typeorm\";\nimport { OpenAI } from \"langchain/llms/openai\";\nimport { SqlDatabase } from \"langchain/sql_db\";\nimport { SqlDatabaseChain } from \"langchain/chains/sql_db\";\nimport { PromptTemplate } from \"langchain/prompts\";\n\nconst template = `Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\nUse the following format:\n\nQuestion: \"Question here\"\nSQLQuery: \"SQL Query to run\"\nSQLResult: \"Result of the SQLQuery\"\nAnswer: \"Final answer here\"\n\nOnly use the following tables:\n\n{table_info}\n\nIf someone asks for the table foobar, they really mean the employee table.\n\nQuestion: {input}`;\n\nconst prompt = PromptTemplate.fromTemplate(template);\n\n/**\n * This example uses Chinook database, which is a sample database available for SQL Server, Oracle, MySQL, etc.\n * To set it up follow the instructions on https://database.guide/2-sample-databases-sqlite/, placing the .db file\n * in the examples folder.\n */\nconst datasource = new DataSource({\n  type: \"sqlite\",\n  database: \"data/Chinook.db\",\n});\n\nconst db = await SqlDatabase.fromDataSourceParams({\n  appDataSource: datasource,\n});\n\nconst chain = new SqlDatabaseChain({\n  llm: new OpenAI({ temperature: 0 }),\n  database: db,\n  sqlOutputKey: \"sql\",\n  prompt,\n});\n\nconst res = await chain.call({\n  query: \"How many employees are there in the foobar table?\",\n});\nconsole.log(res);\n\n/*\n  {\n    result: ' There are 8 employees in the foobar table.',\n    sql: ' SELECT COUNT(*) FROM Employee;'\n  }\n*/"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "(node:2137) Warning: Setting the NODE_TLS_REJECT_UNAUTHORIZED environment variable to '0' makes TLS connections and HTTPS requests insecure by disabling certificate verification.",
                                "(Use `node --trace-warnings ...` to show where the warning was created)",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "{",
                                "  result: ' There are 8 employees in the foobar table.',",
                                "  sql: ' SELECT COUNT(*) FROM Employee;'",
                                "}",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { OpenAI } from \"langchain/llms/openai\";\nimport {\n  loadQAStuffChain,\n  loadQAMapReduceChain,\n  loadQARefineChain\n} from \"langchain/chains\";\nimport { Document } from \"langchain/document\";\n\n// This first example uses the `StuffDocumentsChain`.\nconst llmA = new OpenAI({});\nconst chainA = loadQAStuffChain(llmA);\nconst docs = [\n  new Document({ pageContent: \"Harrison went to Harvard.\" }),\n  new Document({ pageContent: \"Ankush went to Princeton.\" }),\n];\nconst resA = await chainA.call({\n  input_documents: docs,\n  question: \"Where did Harrison go to college?\",\n});\nconsole.log({ resA });\n// { resA: { text: ' Harrison went to Harvard.' } }\n\n// This second example uses the `MapReduceChain`.\n// Optionally limit the number of concurrent requests to the language model.\nconst llmB = new OpenAI({ maxConcurrency: 10 });\nconst chainB = loadQAMapReduceChain(llmB);\nconst resB = await chainB.call({\n  input_documents: docs,\n  question: \"Where did Harrison go to college?\",\n});\nconsole.log({ resB });\n// { resB: { text: ' Harrison went to Harvard.' } }"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "(node:7039) Warning: Setting the NODE_TLS_REJECT_UNAUTHORIZED environment variable to '0' makes TLS connections and HTTPS requests insecure by disabling certificate verification.",
                                "(Use `node --trace-warnings ...` to show where the warning was created)",
                                "{ resB: { text: \" I don't know.\" } }",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "{ resA: { text: ' Harrison went to Harvard.' } }",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { DataSource } from \"typeorm\";\nimport { SqlDatabase } from \"langchain/sql_db\";\nimport { RunnableSequence } from \"langchain/schema/runnable\";\nimport { PromptTemplate } from \"langchain/prompts\";\nimport { StringOutputParser } from \"langchain/schema/output_parser\";\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\n\nconst datasource = new DataSource({\n  type: \"sqlite\",\n  database: \"data/Chinook.db\",\n});\n\nconst db = await SqlDatabase.fromDataSourceParams({\n  appDataSource: datasource,\n});\n\nconst prompt =\n  PromptTemplate.fromTemplate(`Based on the table schema below, write a SQL query that would answer the user's question:\n{schema}\n\nQuestion: {question}\nSQL Query:`);\n\nconst model = new ChatOpenAI();\n\nconst sqlQueryGeneratorChain = RunnableSequence.from([\n  {\n    schema: async () => db.getTableInfo(),\n    question: (input: { question: string }) => input.question,\n  },\n  prompt,\n  model.bind({ stop: [\"\\nSQLResult:\"] }),\n  new StringOutputParser(),\n]);\n\nconst result = await sqlQueryGeneratorChain.invoke({\n  question: \"How many employees are there?\",\n});\n\nconsole.log(result);\n\n/*\n  SELECT COUNT(EmployeeId) AS TotalEmployees FROM Employee\n*/\n\nconst finalResponsePrompt =\n  PromptTemplate.fromTemplate(`Based on the table schema below, question, sql query, and sql response, write a natural language response:\n{schema}\n\nQuestion: {question}\nSQL Query: {query}\nSQL Response: {response}`);\n\nconst fullChain = RunnableSequence.from([\n  {\n    question: (input) => input.question,\n    query: sqlQueryGeneratorChain,\n  },\n  {\n    schema: async () => db.getTableInfo(),\n    question: (input) => input.question,\n    query: (input) => input.query,\n    response: (input) => db.run(input.query),\n  },\n  finalResponsePrompt,\n  model,\n]);\n\nconst finalResponse = await fullChain.invoke({\n  question: \"How many employees are there?\",\n});\n\nconsole.log(finalResponse);\n\n/*\n  AIMessage {\n    content: 'There are 8 employees.',\n    additional_kwargs: { function_call: undefined }\n  }\n*/"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "(node:2504) Warning: Setting the NODE_TLS_REJECT_UNAUTHORIZED environment variable to '0' makes TLS connections and HTTPS requests insecure by disabling certificate verification.",
                                "(Use `node --trace-warnings ...` to show where the warning was created)",
                                "AIMessage {",
                                "  lc_serializable: true,",
                                "  lc_kwargs: {",
                                "    content: 'There are 8 employees.',",
                                "    additional_kwargs: { function_call: undefined }",
                                "  },",
                                "  lc_namespace: [ 'langchain', 'schema' ],",
                                "  content: 'There are 8 employees.',",
                                "  name: undefined,",
                                "  additional_kwargs: { function_call: undefined }",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "SELECT COUNT(*) FROM Employee",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { initializeAgentExecutorWithOptions } from \"langchain/agents\";\nimport { OpenAI } from \"langchain/llms/openai\";\nimport { SerpAPI } from \"langchain/tools\";\nimport { Calculator } from \"langchain/tools/calculator\";\n\nconst model = new OpenAI({ temperature: 0 });\nconst tools = [\n  new SerpAPI(process.env.SERPAPI_API_KEY, {\n    location: \"Austin,Texas,United States\",\n    hl: \"en\",\n    gl: \"us\",\n  }),\n  new Calculator(),\n];\n\nconst executor = await initializeAgentExecutorWithOptions(tools, model, {\n  agentType: \"zero-shot-react-description\",\n  verbose: true,\n});\n\nconst input = `Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?`;\n\nconst result = await executor.call({ input });"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:AgentExecutor\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\"",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:LLMChain > \u001b[1m3:llm:OpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"Answer the following questions as best you can. You have access to the following tools:\\n\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\n\\nUse the following format in your response:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [search,calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\\nThought:\"",
                                "  ]",
                                "}",
                                "\u001b[32m[tool/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m4:tool:SerpAPI\u001b[22m\u001b[39m] Entering Tool run with input: \"Olivia Wilde boyfriend\"",
                                "\u001b[36m[tool/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m4:tool:SerpAPI\u001b[22m\u001b[39m] [2.38s] Exiting Tool run with output: \"[\"Olivia Wilde and Harry Styles took fans by surprise with their whirlwind romance, which began when they met on the set of Don't Worry Darling.\"]\"",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m5:chain:LLMChain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\",",
                                "  \"agent_scratchpad\": \" I need to find out who Olivia Wilde's boyfriend is and then calculate his age raised to the 0.23 power.\\nAction: search\\nAction Input: \\\"Olivia Wilde boyfriend\\\"\\nObservation: [\\\"Olivia Wilde and Harry Styles took fans by surprise with their whirlwind romance, which began when they met on the set of Don't Worry Darling.\\\"]\\nThought:\",",
                                "  \"stop\": [",
                                "    \"\\nObservation: \"",
                                "  ]",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 5:chain:LLMChain > \u001b[1m6:llm:OpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"Answer the following questions as best you can. You have access to the following tools:\\n\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\n\\nUse the following format in your response:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [search,calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\\nThought: I need to find out who Olivia Wilde's boyfriend is and then calculate his age raised to the 0.23 power.\\nAction: search\\nAction Input: \\\"Olivia Wilde boyfriend\\\"\\nObservation: [\\\"Olivia Wilde and Harry Styles took fans by surprise with their whirlwind romance, which began when they met on the set of Don't Worry Darling.\\\"]\\nThought:\"",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 5:chain:LLMChain > \u001b[1m6:llm:OpenAI\u001b[22m\u001b[39m] [1.29s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \" I now know Olivia Wilde's boyfriend is Harry Styles.\\nAction: calculator\\nAction Input: \\\"Harry Styles age^0.23\\\"\",",
                                "        \"generationInfo\": {",
                                "          \"finishReason\": \"stop\",",
                                "          \"logprobs\": null",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 28,",
                                "      \"promptTokens\": 300,",
                                "      \"totalTokens\": 328",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m5:chain:LLMChain\u001b[22m\u001b[39m] [1.77s] Exiting Chain run with output: {",
                                "  \"text\": \" I now know Olivia Wilde's boyfriend is Harry Styles.\\nAction: calculator\\nAction Input: \\\"Harry Styles age^0.23\\\"\"",
                                "}",
                                "\u001b[32m[tool/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m7:tool:Calculator\u001b[22m\u001b[39m] Entering Tool run with input: \"Harry Styles age^0.23\"",
                                "\u001b[36m[tool/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m7:tool:Calculator\u001b[22m\u001b[39m] [229ms] Exiting Tool run with output: \"I don't know how to do that.\"",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m8:chain:LLMChain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\",",
                                "  \"agent_scratchpad\": \" I need to find out who Olivia Wilde's boyfriend is and then calculate his age raised to the 0.23 power.\\nAction: search\\nAction Input: \\\"Olivia Wilde boyfriend\\\"\\nObservation: [\\\"Olivia Wilde and Harry Styles took fans by surprise with their whirlwind romance, which began when they met on the set of Don't Worry Darling.\\\"]\\nThought: I now know Olivia Wilde's boyfriend is Harry Styles.\\nAction: calculator\\nAction Input: \\\"Harry Styles age^0.23\\\"\\nObservation: I don't know how to do that.\\nThought:\",",
                                "  \"stop\": [",
                                "    \"\\nObservation: \"",
                                "  ]",
                                "}",
                                "\u001b[32m[tool/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m10:tool:SerpAPI\u001b[22m\u001b[39m] Entering Tool run with input: \"Harry Styles age\"",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m11:chain:LLMChain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\",",
                                "  \"agent_scratchpad\": \" I need to find out who Olivia Wilde's boyfriend is and then calculate his age raised to the 0.23 power.\\nAction: search\\nAction Input: \\\"Olivia Wilde boyfriend\\\"\\nObservation: [\\\"Olivia Wilde and Harry Styles took fans by surprise with their whirlwind romance, which began when they met on the set of Don't Worry Darling.\\\"]\\nThought: I now know Olivia Wilde's boyfriend is Harry Styles.\\nAction: calculator\\nAction Input: \\\"Harry Styles age^0.23\\\"\\nObservation: I don't know how to do that.\\nThought: I need to find out Harry Styles' age first.\\nAction: search\\nAction Input: \\\"Harry Styles age\\\"\\nObservation: 29 years\\nThought:\",",
                                "  \"stop\": [",
                                "    \"\\nObservation: \"",
                                "  ]",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 11:chain:LLMChain > \u001b[1m12:llm:OpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"Answer the following questions as best you can. You have access to the following tools:\\n\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\n\\nUse the following format in your response:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [search,calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\\nThought: I need to find out who Olivia Wilde's boyfriend is and then calculate his age raised to the 0.23 power.\\nAction: search\\nAction Input: \\\"Olivia Wilde boyfriend\\\"\\nObservation: [\\\"Olivia Wilde and Harry Styles took fans by surprise with their whirlwind romance, which began when they met on the set of Don't Worry Darling.\\\"]\\nThought: I now know Olivia Wilde's boyfriend is Harry Styles.\\nAction: calculator\\nAction Input: \\\"Harry Styles age^0.23\\\"\\nObservation: I don't know how to do that.\\nThought: I need to find out Harry Styles' age first.\\nAction: search\\nAction Input: \\\"Harry Styles age\\\"\\nObservation: 29 years\\nThought:\"",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 11:chain:LLMChain > \u001b[1m12:llm:OpenAI\u001b[22m\u001b[39m] [1.09s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \" I now know Harry Styles' age.\\nAction: calculator\\nAction Input: \\\"29^0.23\\\"\",",
                                "        \"generationInfo\": {",
                                "          \"finishReason\": \"stop\",",
                                "          \"logprobs\": null",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 23,",
                                "      \"promptTokens\": 379,",
                                "      \"totalTokens\": 402",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[34m[agent/action]\u001b[39m [\u001b[90m\u001b[1m1:chain:AgentExecutor\u001b[22m\u001b[39m] Agent selected action: {",
                                "  \"tool\": \"calculator\",",
                                "  \"toolInput\": \"29^0.23\",",
                                "  \"log\": \" I now know Harry Styles' age.\\nAction: calculator\\nAction Input: \\\"29^0.23\\\"\"",
                                "}",
                                "\u001b[32m[tool/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m13:tool:Calculator\u001b[22m\u001b[39m] Entering Tool run with input: \"29^0.23\"",
                                "\u001b[36m[tool/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m13:tool:Calculator\u001b[22m\u001b[39m] [229ms] Exiting Tool run with output: \"2.169459462491557\"",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m14:chain:LLMChain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\",",
                                "  \"agent_scratchpad\": \" I need to find out who Olivia Wilde's boyfriend is and then calculate his age raised to the 0.23 power.\\nAction: search\\nAction Input: \\\"Olivia Wilde boyfriend\\\"\\nObservation: [\\\"Olivia Wilde and Harry Styles took fans by surprise with their whirlwind romance, which began when they met on the set of Don't Worry Darling.\\\"]\\nThought: I now know Olivia Wilde's boyfriend is Harry Styles.\\nAction: calculator\\nAction Input: \\\"Harry Styles age^0.23\\\"\\nObservation: I don't know how to do that.\\nThought: I need to find out Harry Styles' age first.\\nAction: search\\nAction Input: \\\"Harry Styles age\\\"\\nObservation: 29 years\\nThought: I now know Harry Styles' age.\\nAction: calculator\\nAction Input: \\\"29^0.23\\\"\\nObservation: 2.169459462491557\\nThought:\",",
                                "  \"stop\": [",
                                "    \"\\nObservation: \"",
                                "  ]",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 14:chain:LLMChain > \u001b[1m15:llm:OpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"prompts\": [",
                                "    \"Answer the following questions as best you can. You have access to the following tools:\\n\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\n\\nUse the following format in your response:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [search,calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\\nThought: I need to find out who Olivia Wilde's boyfriend is and then calculate his age raised to the 0.23 power.\\nAction: search\\nAction Input: \\\"Olivia Wilde boyfriend\\\"\\nObservation: [\\\"Olivia Wilde and Harry Styles took fans by surprise with their whirlwind romance, which began when they met on the set of Don't Worry Darling.\\\"]\\nThought: I now know Olivia Wilde's boyfriend is Harry Styles.\\nAction: calculator\\nAction Input: \\\"Harry Styles age^0.23\\\"\\nObservation: I don't know how to do that.\\nThought: I need to find out Harry Styles' age first.\\nAction: search\\nAction Input: \\\"Harry Styles age\\\"\\nObservation: 29 years\\nThought: I now know Harry Styles' age.\\nAction: calculator\\nAction Input: \\\"29^0.23\\\"\\nObservation: 2.169459462491557\\nThought:\"",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 14:chain:LLMChain > \u001b[1m15:llm:OpenAI\u001b[22m\u001b[39m] [1.11s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \" I now know the final answer.\\nFinal Answer: Harry Styles' age raised to the 0.23 power is 2.169459462491557.\",",
                                "        \"generationInfo\": {",
                                "          \"finishReason\": \"stop\",",
                                "          \"logprobs\": null",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 32,",
                                "      \"promptTokens\": 418,",
                                "      \"totalTokens\": 450",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:AgentExecutor\u001b[22m\u001b[39m] [18.85s] Exiting Chain run with output: {",
                                "  \"output\": \"Harry Styles' age raised to the 0.23 power is 2.169459462491557.\"",
                                "}",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "(node:8175) Warning: Setting the NODE_TLS_REJECT_UNAUTHORIZED environment variable to '0' makes TLS connections and HTTPS requests insecure by disabling certificate verification.",
                                "(Use `node --trace-warnings ...` to show where the warning was created)",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m2:chain:LLMChain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\",",
                                "  \"agent_scratchpad\": \"\",",
                                "  \"stop\": [",
                                "    \"\\nObservation: \"",
                                "  ]",
                                "}",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { Calculator } from \"langchain/tools/calculator\";\nimport { SerpAPI } from \"langchain/tools\";\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport { PlanAndExecuteAgentExecutor } from \"langchain/experimental/plan_and_execute\";\n\nconst tools = [new Calculator(), new SerpAPI()];\nconst model = new ChatOpenAI({\n  temperature: 0,\n  modelName: \"gpt-3.5-turbo\",\n  verbose: true,\n});\nconst executor = PlanAndExecuteAgentExecutor.fromLLMAndTools({\n  llm: model,\n  tools,\n});\n\nconst result = await executor.call({\n  input: `Who is the current president of the United States? What is their current age raised to the second power?`,\n});\n\nconsole.log({ result });"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Let's first understand the problem and devise a plan to solve the problem. Please output the plan starting with the header \\\"Plan:\\\" and then followed by a numbered list of steps. Please make the plan the minimum number of steps required to answer the query or complete the task accurately and precisely. Your steps should be general, and should not require a specific method to solve a step. If the task is a question, the final step in the plan must be the following: \\\"Given the above steps taken, please respond to the original query.\\\" At the end of your plan, say \\\"<END_OF_PLAN>\\\"\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Who is the current president of the United States? What is their current age raised to the second power?\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.80s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"Plan:\\n1. Find the current president of the United States.\\n2. Determine their current age.\\n3. Calculate their current age raised to the second power.\\n4. Given the above steps taken, respond to the original query.\\n\\n<END_OF_PLAN>\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"Plan:\\n1. Find the current president of the United States.\\n2. Determine their current age.\\n3. Calculate their current age raised to the second power.\\n4. Given the above steps taken, respond to the original query.\\n\\n<END_OF_PLAN>\",",
                                "            \"additional_kwargs\": {}",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"stop\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 51,",
                                "      \"promptTokens\": 153,",
                                "      \"totalTokens\": 204",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob, denoted below by $JSON_BLOB\\nSpecifically, this $JSON_BLOB should have a \\\"action\\\" key (with the name of the tool to use) and a \\\"action_input\\\" key (with the input to the tool going here). \\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"1 + 2\\\"\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: \\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Previous steps: []\\n\\nCurrent objective: Find the current president of the United States.\\n\\n\\n\\nYou may extract and combine relevant data from your previous steps when responding to me.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.75s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"Thought: I need to use the search tool to find the current president of the United States.\\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"search\\\",\\n  \\\"action_input\\\": \\\"current president of the United States\\\"\\n}\\n```\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"Thought: I need to use the search tool to find the current president of the United States.\\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"search\\\",\\n  \\\"action_input\\\": \\\"current president of the United States\\\"\\n}\\n```\",",
                                "            \"additional_kwargs\": {}",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"stop\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 46,",
                                "      \"promptTokens\": 338,",
                                "      \"totalTokens\": 384",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob, denoted below by $JSON_BLOB\\nSpecifically, this $JSON_BLOB should have a \\\"action\\\" key (with the name of the tool to use) and a \\\"action_input\\\" key (with the input to the tool going here). \\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"1 + 2\\\"\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: \\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Previous steps: []\\n\\nCurrent objective: Find the current president of the United States.\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nThought: I need to use the search tool to find the current president of the United States.\\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"search\\\",\\n  \\\"action_input\\\": \\\"current president of the United States\\\"\\n}\\n```\\nObservation: Joe Biden\\nThought:\\n\\nYou may extract and combine relevant data from your previous steps when responding to me.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.87s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"Thought: The search tool returned the name \\\"Joe Biden\\\" as the current president of the United States.\\n\\nFinal Answer: The current president of the United States is Joe Biden.\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"Thought: The search tool returned the name \\\"Joe Biden\\\" as the current president of the United States.\\n\\nFinal Answer: The current president of the United States is Joe Biden.\",",
                                "            \"additional_kwargs\": {}",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"stop\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 35,",
                                "      \"promptTokens\": 418,",
                                "      \"totalTokens\": 453",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob, denoted below by $JSON_BLOB\\nSpecifically, this $JSON_BLOB should have a \\\"action\\\" key (with the name of the tool to use) and a \\\"action_input\\\" key (with the input to the tool going here). \\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"1 + 2\\\"\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: \\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Previous steps: [{\\\"action\\\":{\\\"text\\\":\\\"Find the current president of the United States.\\\"},\\\"result\\\":{\\\"response\\\":\\\"The current president of the United States is Joe Biden.\\\"}}]\\n\\nCurrent objective: Determine their current age.\\n\\n\\n\\nYou may extract and combine relevant data from your previous steps when responding to me.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.97s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"Thought: To determine Joe Biden's current age, I can search for his date of birth and calculate the difference between his birthdate and the current date.\\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"search\\\",\\n  \\\"action_input\\\": \\\"Joe Biden date of birth\\\"\\n}\\n```\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"Thought: To determine Joe Biden's current age, I can search for his date of birth and calculate the difference between his birthdate and the current date.\\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"search\\\",\\n  \\\"action_input\\\": \\\"Joe Biden date of birth\\\"\\n}\\n```\",",
                                "            \"additional_kwargs\": {}",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"stop\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 57,",
                                "      \"promptTokens\": 365,",
                                "      \"totalTokens\": 422",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob, denoted below by $JSON_BLOB\\nSpecifically, this $JSON_BLOB should have a \\\"action\\\" key (with the name of the tool to use) and a \\\"action_input\\\" key (with the input to the tool going here). \\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"1 + 2\\\"\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: \\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Previous steps: [{\\\"action\\\":{\\\"text\\\":\\\"Find the current president of the United States.\\\"},\\\"result\\\":{\\\"response\\\":\\\"The current president of the United States is Joe Biden.\\\"}}]\\n\\nCurrent objective: Determine their current age.\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nThought: To determine Joe Biden's current age, I can search for his date of birth and calculate the difference between his birthdate and the current date.\\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"search\\\",\\n  \\\"action_input\\\": \\\"Joe Biden date of birth\\\"\\n}\\n```\\nObservation: November 20, 1942\\nThought:\\n\\nYou may extract and combine relevant data from your previous steps when responding to me.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.99s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"Thought: Now that I have found Joe Biden's date of birth, I can calculate his current age by subtracting his birthdate from the current date.\\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"2022 - 1942\\\"\\n}\\n```\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"Thought: Now that I have found Joe Biden's date of birth, I can calculate his current age by subtracting his birthdate from the current date.\\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"2022 - 1942\\\"\\n}\\n```\",",
                                "            \"additional_kwargs\": {}",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"stop\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 58,",
                                "      \"promptTokens\": 461,",
                                "      \"totalTokens\": 519",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob, denoted below by $JSON_BLOB\\nSpecifically, this $JSON_BLOB should have a \\\"action\\\" key (with the name of the tool to use) and a \\\"action_input\\\" key (with the input to the tool going here). \\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"1 + 2\\\"\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: \\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Previous steps: [{\\\"action\\\":{\\\"text\\\":\\\"Find the current president of the United States.\\\"},\\\"result\\\":{\\\"response\\\":\\\"The current president of the United States is Joe Biden.\\\"}}]\\n\\nCurrent objective: Determine their current age.\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nThought: To determine Joe Biden's current age, I can search for his date of birth and calculate the difference between his birthdate and the current date.\\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"search\\\",\\n  \\\"action_input\\\": \\\"Joe Biden date of birth\\\"\\n}\\n```\\nObservation: November 20, 1942\\nThought:Thought: Now that I have found Joe Biden's date of birth, I can calculate his current age by subtracting his birthdate from the current date.\\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"2022 - 1942\\\"\\n}\\n```\\nObservation: 80\\nThought:\\n\\nYou may extract and combine relevant data from your previous steps when responding to me.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.21s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"Final Answer: Joe Biden's current age is 80.\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"Final Answer: Joe Biden's current age is 80.\",",
                                "            \"additional_kwargs\": {}",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"stop\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 12,",
                                "      \"promptTokens\": 528,",
                                "      \"totalTokens\": 540",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob, denoted below by $JSON_BLOB\\nSpecifically, this $JSON_BLOB should have a \\\"action\\\" key (with the name of the tool to use) and a \\\"action_input\\\" key (with the input to the tool going here). \\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"1 + 2\\\"\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: \\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Previous steps: [{\\\"action\\\":{\\\"text\\\":\\\"Find the current president of the United States.\\\"},\\\"result\\\":{\\\"response\\\":\\\"The current president of the United States is Joe Biden.\\\"}},{\\\"action\\\":{\\\"text\\\":\\\"Determine their current age.\\\"},\\\"result\\\":{\\\"response\\\":\\\"Joe Biden's current age is 80.\\\"}}]\\n\\nCurrent objective: Calculate their current age raised to the second power.\\n\\n\\n\\nYou may extract and combine relevant data from your previous steps when responding to me.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [2.36s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"Thought: To calculate Joe Biden's current age raised to the second power, I can use the information from the previous steps.\\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"80^2\\\"\\n}\\n```\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"Thought: To calculate Joe Biden's current age raised to the second power, I can use the information from the previous steps.\\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"80^2\\\"\\n}\\n```\",",
                                "            \"additional_kwargs\": {}",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"stop\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 49,",
                                "      \"promptTokens\": 396,",
                                "      \"totalTokens\": 445",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob, denoted below by $JSON_BLOB\\nSpecifically, this $JSON_BLOB should have a \\\"action\\\" key (with the name of the tool to use) and a \\\"action_input\\\" key (with the input to the tool going here). \\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"1 + 2\\\"\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: \\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Previous steps: [{\\\"action\\\":{\\\"text\\\":\\\"Find the current president of the United States.\\\"},\\\"result\\\":{\\\"response\\\":\\\"The current president of the United States is Joe Biden.\\\"}},{\\\"action\\\":{\\\"text\\\":\\\"Determine their current age.\\\"},\\\"result\\\":{\\\"response\\\":\\\"Joe Biden's current age is 80.\\\"}}]\\n\\nCurrent objective: Calculate their current age raised to the second power.\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nThought: To calculate Joe Biden's current age raised to the second power, I can use the information from the previous steps.\\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"80^2\\\"\\n}\\n```\\nObservation: 6400\\nThought:\\n\\nYou may extract and combine relevant data from your previous steps when responding to me.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob, denoted below by $JSON_BLOB\\nSpecifically, this $JSON_BLOB should have a \\\"action\\\" key (with the name of the tool to use) and a \\\"action_input\\\" key (with the input to the tool going here). \\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"1 + 2\\\"\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: \\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Previous steps: [{\\\"action\\\":{\\\"text\\\":\\\"Find the current president of the United States.\\\"},\\\"result\\\":{\\\"response\\\":\\\"The current president of the United States is Joe Biden.\\\"}},{\\\"action\\\":{\\\"text\\\":\\\"Determine their current age.\\\"},\\\"result\\\":{\\\"response\\\":\\\"Joe Biden's current age is 80.\\\"}}]\\n\\nCurrent objective: Calculate their current age raised to the second power.\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nThought: To calculate Joe Biden's current age raised to the second power, I can use the information from the previous steps.\\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"80^2\\\"\\n}\\n```\\nObservation: 6400\\nThought:Thought: Now that I have the result from the previous step, I can calculate Joe Biden's current age raised to the second power.\\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"6400\\\"\\n}\\n```\\n\\n\\nObservation: 6400\\nThought:\\n\\nYou may extract and combine relevant data from your previous steps when responding to me.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.84s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"Final Answer: Joe Biden's current age raised to the second power is 6400.\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"Final Answer: Joe Biden's current age raised to the second power is 6400.\",",
                                "            \"additional_kwargs\": {}",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"stop\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 18,",
                                "      \"promptTokens\": 540,",
                                "      \"totalTokens\": 558",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob, denoted below by $JSON_BLOB\\nSpecifically, this $JSON_BLOB should have a \\\"action\\\" key (with the name of the tool to use) and a \\\"action_input\\\" key (with the input to the tool going here). \\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": \\\"calculator\\\",\\n  \\\"action_input\\\": \\\"1 + 2\\\"\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: \\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Previous steps: [{\\\"action\\\":{\\\"text\\\":\\\"Find the current president of the United States.\\\"},\\\"result\\\":{\\\"response\\\":\\\"The current president of the United States is Joe Biden.\\\"}},{\\\"action\\\":{\\\"text\\\":\\\"Determine their current age.\\\"},\\\"result\\\":{\\\"response\\\":\\\"Joe Biden's current age is 80.\\\"}},{\\\"action\\\":{\\\"text\\\":\\\"Calculate their current age raised to the second power.\\\"},\\\"result\\\":{\\\"response\\\":\\\"Joe Biden's current age raised to the second power is 6400.\\\"}}]\\n\\nCurrent objective: Given the above steps taken, respond to the original query.\\n\\n The original question was: Who is the current president of the United States? What is their current age raised to the second power?.\\n\\n\\n\\nYou may extract and combine relevant data from your previous steps when responding to me.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [2.38s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"Final Answer: The current president of the United States is Joe Biden. His current age raised to the second power is 6400.\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"Final Answer: The current president of the United States is Joe Biden. His current age raised to the second power is 6400.\",",
                                "            \"additional_kwargs\": {}",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"stop\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 27,",
                                "      \"promptTokens\": 461,",
                                "      \"totalTokens\": 488",
                                "    }",
                                "  }",
                                "}",
                                "{",
                                "  result: {",
                                "    output: 'The current president of the United States is Joe Biden. His current age raised to the second power is 6400.'",
                                "  }",
                                "}",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { initializeAgentExecutorWithOptions } from \"langchain/agents\";\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport { SerpAPI } from \"langchain/tools\";\nimport { Calculator } from \"langchain/tools/calculator\";\n\nconst tools = [new Calculator(), new SerpAPI()];\nconst chat = new ChatOpenAI({ modelName: \"gpt-3.5-turbo\", temperature: 0 });\n\nconst executor = await initializeAgentExecutorWithOptions(tools, chat, {\n  agentType: \"openai-functions\",\n  verbose: true,\n});\n\nconst result = await executor.run(\"What is the weather in New York?\");\nconsole.log(result);\n\n/*\n  The current weather in New York is 72°F with a wind speed of 1 mph coming from the SSW. The humidity is at 89% and the UV index is 0 out of 11. The cloud cover is 79% and there has been no rain.\n*/"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:AgentExecutor\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"What is the weather in New York?\",",
                                "  \"chat_history\": []",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"You are a helpful AI assistant.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"What is the weather in New York?\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.30s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"\",",
                                "            \"additional_kwargs\": {",
                                "              \"function_call\": {",
                                "                \"name\": \"search\",",
                                "                \"arguments\": \"{\\n  \\\"input\\\": \\\"weather in New York\\\"\\n}\"",
                                "              }",
                                "            }",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"function_call\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 17,",
                                "      \"promptTokens\": 121,",
                                "      \"totalTokens\": 138",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[32m[tool/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m3:tool:SerpAPI\u001b[22m\u001b[39m] Entering Tool run with input: \"weather in New York\"",
                                "\u001b[36m[tool/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m3:tool:SerpAPI\u001b[22m\u001b[39m] [2.97s] Exiting Tool run with output: \"{\"type\":\"weather_result\",\"temperature\":\"66\",\"unit\":\"Fahrenheit\",\"precipitation\":\"4%\",\"humidity\":\"84%\",\"wind\":\"5 mph\",\"location\":\"New York, NY\",\"date\":\"Wednesday 6:00 AM\",\"weather\":\"Clear\"}\"",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m4:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"You are a helpful AI assistant.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"What is the weather in New York?\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"AIMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"\",",
                                "          \"additional_kwargs\": {",
                                "            \"function_call\": {",
                                "              \"name\": \"search\",",
                                "              \"arguments\": \"{\\n  \\\"input\\\": \\\"weather in New York\\\"\\n}\"",
                                "            }",
                                "          }",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"FunctionMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"{\\\"type\\\":\\\"weather_result\\\",\\\"temperature\\\":\\\"66\\\",\\\"unit\\\":\\\"Fahrenheit\\\",\\\"precipitation\\\":\\\"4%\\\",\\\"humidity\\\":\\\"84%\\\",\\\"wind\\\":\\\"5 mph\\\",\\\"location\\\":\\\"New York, NY\\\",\\\"date\\\":\\\"Wednesday 6:00 AM\\\",\\\"weather\\\":\\\"Clear\\\"}\",",
                                "          \"name\": \"search\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "The weather in New York is currently clear with a temperature of 66°F. There is a 4% chance of precipitation, and the humidity is at 84%. The wind speed is 5 mph.",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport { initializeAgentExecutorWithOptions } from \"langchain/agents\";\nimport { SerpAPI } from \"langchain/tools\";\nimport { Calculator } from \"langchain/tools/calculator\";\n\nconst model = new ChatOpenAI({ temperature: 0 });\nconst tools = [\n  new SerpAPI(process.env.SERPAPI_API_KEY, {\n    location: \"Austin,Texas,United States\",\n    hl: \"en\",\n    gl: \"us\",\n  }),\n  new Calculator(),\n];\n\n// Passing \"chat-conversational-react-description\" as the agent type\n// automatically creates and uses BufferMemory with the executor.\n// If you would like to override this, you can pass in a custom\n// memory option, but the memoryKey set on it must be \"chat_history\".\nconst executor = await initializeAgentExecutorWithOptions(tools, model, {\n  agentType: \"chat-conversational-react-description\",\n  verbose: true,\n});\nconsole.log(\"Loaded agent.\");\n\nconst input0 = \"hi, i am bob\";\n\nconst result0 = await executor.call({ input: input0 });\n\nconsole.log(`Got output ${result0.output}`);\n\nconst input1 = \"whats my name?\";\n\nconst result1 = await executor.call({ input: input1 });\n\nconsole.log(`Got output ${result1.output}`);\n\nconst input2 = \"whats the weather in pomfret?\";\n\nconst result2 = await executor.call({ input: input2 });\n\nconsole.log(`Got output ${result2.output}`);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "Loaded agent.",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:AgentExecutor\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"hi, i am bob\",",
                                "  \"chat_history\": []",
                                "}",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m2:chain:LLMChain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"hi, i am bob\",",
                                "  \"chat_history\": [],",
                                "  \"agent_scratchpad\": [],",
                                "  \"stop\": [",
                                "    \"Observation:\"",
                                "  ]",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:LLMChain > \u001b[1m3:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist. However, above all else, all responses must adhere to the format of RESPONSE FORMAT INSTRUCTIONS.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nOutput a JSON markdown code snippet containing a valid JSON object in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, // The action to take. Must be one of [search, calculator]\\n    \\\"action_input\\\": string // The input to the action. May be a stringified object.\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly and conversationally to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string // You should put what you want to return to use here and make sure to use valid json newline characters.\\n}\\n```\\n\\nFor both options, remember to always include the surrounding markdown code snippet delimiters (begin with \\\"```json\\\" and end with \\\"```\\\")!\\n\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\nhi, i am bob\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:LLMChain > \u001b[1m3:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.63s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Hello Bob! How can I assist you today?\\\"\\n}\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Hello Bob! How can I assist you today?\\\"\\n}\",",
                                "            \"additional_kwargs\": {}",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"stop\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 26,",
                                "      \"promptTokens\": 583,",
                                "      \"totalTokens\": 609",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:AgentExecutor\u001b[22m\u001b[39m] [2.72s] Exiting Chain run with output: {",
                                "  \"output\": \"Hello Bob! How can I assist you today?\"",
                                "}",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:AgentExecutor\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"whats my name?\",",
                                "  \"chat_history\": [",
                                "    {",
                                "      \"lc\": 1,",
                                "      \"type\": \"constructor\",",
                                "      \"id\": [",
                                "        \"langchain\",",
                                "        \"schema\",",
                                "        \"HumanMessage\"",
                                "      ],",
                                "      \"kwargs\": {",
                                "        \"content\": \"hi, i am bob\",",
                                "        \"additional_kwargs\": {}",
                                "      }",
                                "    },",
                                "    {",
                                "      \"lc\": 1,",
                                "      \"type\": \"constructor\",",
                                "      \"id\": [",
                                "        \"langchain\",",
                                "        \"schema\",",
                                "        \"AIMessage\"",
                                "      ],",
                                "      \"kwargs\": {",
                                "        \"content\": \"Hello Bob! How can I assist you today?\",",
                                "        \"additional_kwargs\": {}",
                                "      }",
                                "    }",
                                "  ]",
                                "}",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m2:chain:LLMChain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"whats my name?\",",
                                "  \"chat_history\": [",
                                "    {",
                                "      \"lc\": 1,",
                                "      \"type\": \"constructor\",",
                                "      \"id\": [",
                                "        \"langchain\",",
                                "        \"schema\",",
                                "        \"HumanMessage\"",
                                "      ],",
                                "      \"kwargs\": {",
                                "        \"content\": \"hi, i am bob\",",
                                "        \"additional_kwargs\": {}",
                                "      }",
                                "    },",
                                "    {",
                                "      \"lc\": 1,",
                                "      \"type\": \"constructor\",",
                                "      \"id\": [",
                                "        \"langchain\",",
                                "        \"schema\",",
                                "        \"AIMessage\"",
                                "      ],",
                                "      \"kwargs\": {",
                                "        \"content\": \"Hello Bob! How can I assist you today?\",",
                                "        \"additional_kwargs\": {}",
                                "      }",
                                "    }",
                                "  ],",
                                "  \"agent_scratchpad\": [],",
                                "  \"stop\": [",
                                "    \"Observation:\"",
                                "  ]",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:LLMChain > \u001b[1m3:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist. However, above all else, all responses must adhere to the format of RESPONSE FORMAT INSTRUCTIONS.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"hi, i am bob\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"AIMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Hello Bob! How can I assist you today?\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nOutput a JSON markdown code snippet containing a valid JSON object in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, // The action to take. Must be one of [search, calculator]\\n    \\\"action_input\\\": string // The input to the action. May be a stringified object.\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly and conversationally to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string // You should put what you want to return to use here and make sure to use valid json newline characters.\\n}\\n```\\n\\nFor both options, remember to always include the surrounding markdown code snippet delimiters (begin with \\\"```json\\\" and end with \\\"```\\\")!\\n\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\nwhats my name?\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m2:chain:LLMChain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"whats the weather in pomfret?\",",
                                "  \"chat_history\": [",
                                "    {",
                                "      \"lc\": 1,",
                                "      \"type\": \"constructor\",",
                                "      \"id\": [",
                                "        \"langchain\",",
                                "        \"schema\",",
                                "        \"HumanMessage\"",
                                "      ],",
                                "      \"kwargs\": {",
                                "        \"content\": \"hi, i am bob\",",
                                "        \"additional_kwargs\": {}",
                                "      }",
                                "    },",
                                "    {",
                                "      \"lc\": 1,",
                                "      \"type\": \"constructor\",",
                                "      \"id\": [",
                                "        \"langchain\",",
                                "        \"schema\",",
                                "        \"AIMessage\"",
                                "      ],",
                                "      \"kwargs\": {",
                                "        \"content\": \"Hello Bob! How can I assist you today?\",",
                                "        \"additional_kwargs\": {}",
                                "      }",
                                "    },",
                                "    {",
                                "      \"lc\": 1,",
                                "      \"type\": \"constructor\",",
                                "      \"id\": [",
                                "        \"langchain\",",
                                "        \"schema\",",
                                "        \"HumanMessage\"",
                                "      ],",
                                "      \"kwargs\": {",
                                "        \"content\": \"whats my name?\",",
                                "        \"additional_kwargs\": {}",
                                "      }",
                                "    },",
                                "    {",
                                "      \"lc\": 1,",
                                "      \"type\": \"constructor\",",
                                "      \"id\": [",
                                "        \"langchain\",",
                                "        \"schema\",",
                                "        \"AIMessage\"",
                                "      ],",
                                "      \"kwargs\": {",
                                "        \"content\": \"Your name is Bob.\",",
                                "        \"additional_kwargs\": {}",
                                "      }",
                                "    }",
                                "  ],",
                                "  \"agent_scratchpad\": [],",
                                "  \"stop\": [",
                                "    \"Observation:\"",
                                "  ]",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:LLMChain > \u001b[1m3:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist. However, above all else, all responses must adhere to the format of RESPONSE FORMAT INSTRUCTIONS.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"hi, i am bob\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"AIMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Hello Bob! How can I assist you today?\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"whats my name?\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"AIMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Your name is Bob.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nOutput a JSON markdown code snippet containing a valid JSON object in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, // The action to take. Must be one of [search, calculator]\\n    \\\"action_input\\\": string // The input to the action. May be a stringified object.\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly and conversationally to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string // You should put what you want to return to use here and make sure to use valid json newline characters.\\n}\\n```\\n\\nFor both options, remember to always include the surrounding markdown code snippet delimiters (begin with \\\"```json\\\" and end with \\\"```\\\")!\\n\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\nwhats the weather in pomfret?\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:LLMChain > \u001b[1m3:llm:ChatOpenAI\u001b[22m\u001b[39m] [2.04s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"{\\n    \\\"action\\\": \\\"search\\\",\\n    \\\"action_input\\\": \\\"weather in Pomfret\\\"\\n}\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"{\\n    \\\"action\\\": \\\"search\\\",\\n    \\\"action_input\\\": \\\"weather in Pomfret\\\"\\n}\",",
                                "            \"additional_kwargs\": {}",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"stop\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 21,",
                                "      \"promptTokens\": 628,",
                                "      \"totalTokens\": 649",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m2:chain:LLMChain\u001b[22m\u001b[39m] [2.52s] Exiting Chain run with output: {",
                                "  \"text\": \"{\\n    \\\"action\\\": \\\"search\\\",\\n    \\\"action_input\\\": \\\"weather in Pomfret\\\"\\n}\"",
                                "}",
                                "\u001b[32m[tool/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m4:tool:SerpAPI\u001b[22m\u001b[39m] Entering Tool run with input: \"weather in Pomfret\"",
                                "\u001b[36m[tool/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m4:tool:SerpAPI\u001b[22m\u001b[39m] [4.12s] Exiting Tool run with output: \"{\"type\":\"weather_result\",\"temperature\":\"55\",\"unit\":\"Fahrenheit\",\"precipitation\":\"4%\",\"humidity\":\"100%\",\"wind\":\"2 mph\",\"location\":\"Pomfret, CT\",\"date\":\"Wednesday 6:00 AM\",\"weather\":\"Clear\"}\"",
                                "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m5:chain:LLMChain\u001b[22m\u001b[39m] Entering Chain run with input: {",
                                "  \"input\": \"whats the weather in pomfret?\",",
                                "  \"chat_history\": [",
                                "    {",
                                "      \"lc\": 1,",
                                "      \"type\": \"constructor\",",
                                "      \"id\": [",
                                "        \"langchain\",",
                                "        \"schema\",",
                                "        \"HumanMessage\"",
                                "      ],",
                                "      \"kwargs\": {",
                                "        \"content\": \"hi, i am bob\",",
                                "        \"additional_kwargs\": {}",
                                "      }",
                                "    },",
                                "    {",
                                "      \"lc\": 1,",
                                "      \"type\": \"constructor\",",
                                "      \"id\": [",
                                "        \"langchain\",",
                                "        \"schema\",",
                                "        \"AIMessage\"",
                                "      ],",
                                "      \"kwargs\": {",
                                "        \"content\": \"Hello Bob! How can I assist you today?\",",
                                "        \"additional_kwargs\": {}",
                                "      }",
                                "    },",
                                "    {",
                                "      \"lc\": 1,",
                                "      \"type\": \"constructor\",",
                                "      \"id\": [",
                                "        \"langchain\",",
                                "        \"schema\",",
                                "        \"HumanMessage\"",
                                "      ],",
                                "      \"kwargs\": {",
                                "        \"content\": \"whats my name?\",",
                                "        \"additional_kwargs\": {}",
                                "      }",
                                "    },",
                                "    {",
                                "      \"lc\": 1,",
                                "      \"type\": \"constructor\",",
                                "      \"id\": [",
                                "        \"langchain\",",
                                "        \"schema\",",
                                "        \"AIMessage\"",
                                "      ],",
                                "      \"kwargs\": {",
                                "        \"content\": \"Your name is Bob.\",",
                                "        \"additional_kwargs\": {}",
                                "      }",
                                "    }",
                                "  ],",
                                "  \"agent_scratchpad\": [",
                                "    {",
                                "      \"lc\": 1,",
                                "      \"type\": \"constructor\",",
                                "      \"id\": [",
                                "        \"langchain\",",
                                "        \"schema\",",
                                "        \"AIMessage\"",
                                "      ],",
                                "      \"kwargs\": {",
                                "        \"content\": \"{\\n    \\\"action\\\": \\\"search\\\",\\n    \\\"action_input\\\": \\\"weather in Pomfret\\\"\\n}\",",
                                "        \"additional_kwargs\": {}",
                                "      }",
                                "    },",
                                "    {",
                                "      \"lc\": 1,",
                                "      \"type\": \"constructor\",",
                                "      \"id\": [",
                                "        \"langchain\",",
                                "        \"schema\",",
                                "        \"HumanMessage\"",
                                "      ],",
                                "      \"kwargs\": {",
                                "        \"content\": \"TOOL RESPONSE:\\n---------------------\\n{\\\"type\\\":\\\"weather_result\\\",\\\"temperature\\\":\\\"55\\\",\\\"unit\\\":\\\"Fahrenheit\\\",\\\"precipitation\\\":\\\"4%\\\",\\\"humidity\\\":\\\"100%\\\",\\\"wind\\\":\\\"2 mph\\\",\\\"location\\\":\\\"Pomfret, CT\\\",\\\"date\\\":\\\"Wednesday 6:00 AM\\\",\\\"weather\\\":\\\"Clear\\\"}\\n\\nUSER'S INPUT\\n--------------------\\n\\nOkay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\",",
                                "        \"additional_kwargs\": {}",
                                "      }",
                                "    }",
                                "  ],",
                                "  \"stop\": [",
                                "    \"Observation:\"",
                                "  ]",
                                "}",
                                "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 5:chain:LLMChain > \u001b[1m6:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {",
                                "  \"messages\": [",
                                "    [",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"SystemMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist. However, above all else, all responses must adhere to the format of RESPONSE FORMAT INSTRUCTIONS.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"hi, i am bob\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"AIMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Hello Bob! How can I assist you today?\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"whats my name?\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"AIMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"Your name is Bob.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\nsearch: a search engine. useful for when you need to answer questions about current events. input should be a search query.\\ncalculator: Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nOutput a JSON markdown code snippet containing a valid JSON object in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, // The action to take. Must be one of [search, calculator]\\n    \\\"action_input\\\": string // The input to the action. May be a stringified object.\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly and conversationally to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string // You should put what you want to return to use here and make sure to use valid json newline characters.\\n}\\n```\\n\\nFor both options, remember to always include the surrounding markdown code snippet delimiters (begin with \\\"```json\\\" and end with \\\"```\\\")!\\n\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\nwhats the weather in pomfret?\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"AIMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"{\\n    \\\"action\\\": \\\"search\\\",\\n    \\\"action_input\\\": \\\"weather in Pomfret\\\"\\n}\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      },",
                                "      {",
                                "        \"lc\": 1,",
                                "        \"type\": \"constructor\",",
                                "        \"id\": [",
                                "          \"langchain\",",
                                "          \"schema\",",
                                "          \"HumanMessage\"",
                                "        ],",
                                "        \"kwargs\": {",
                                "          \"content\": \"TOOL RESPONSE:\\n---------------------\\n{\\\"type\\\":\\\"weather_result\\\",\\\"temperature\\\":\\\"55\\\",\\\"unit\\\":\\\"Fahrenheit\\\",\\\"precipitation\\\":\\\"4%\\\",\\\"humidity\\\":\\\"100%\\\",\\\"wind\\\":\\\"2 mph\\\",\\\"location\\\":\\\"Pomfret, CT\\\",\\\"date\\\":\\\"Wednesday 6:00 AM\\\",\\\"weather\\\":\\\"Clear\\\"}\\n\\nUSER'S INPUT\\n--------------------\\n\\nOkay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\",",
                                "          \"additional_kwargs\": {}",
                                "        }",
                                "      }",
                                "    ]",
                                "  ]",
                                "}",
                                "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 5:chain:LLMChain > \u001b[1m6:llm:ChatOpenAI\u001b[22m\u001b[39m] [4.40s] Exiting LLM run with output: {",
                                "  \"generations\": [",
                                "    [",
                                "      {",
                                "        \"text\": \"{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"The weather in Pomfret, CT is currently clear with a temperature of 55 degrees Fahrenheit. There is a 4% chance of precipitation, humidity is at 100%, and the wind speed is 2 mph. This information is as of Wednesday 6:00 AM.\\\"\\n}\",",
                                "        \"message\": {",
                                "          \"lc\": 1,",
                                "          \"type\": \"constructor\",",
                                "          \"id\": [",
                                "            \"langchain\",",
                                "            \"schema\",",
                                "            \"AIMessage\"",
                                "          ],",
                                "          \"kwargs\": {",
                                "            \"content\": \"{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"The weather in Pomfret, CT is currently clear with a temperature of 55 degrees Fahrenheit. There is a 4% chance of precipitation, humidity is at 100%, and the wind speed is 2 mph. This information is as of Wednesday 6:00 AM.\\\"\\n}\",",
                                "            \"additional_kwargs\": {}",
                                "          }",
                                "        },",
                                "        \"generationInfo\": {",
                                "          \"finish_reason\": \"stop\"",
                                "        }",
                                "      }",
                                "    ]",
                                "  ],",
                                "  \"llmOutput\": {",
                                "    \"tokenUsage\": {",
                                "      \"completionTokens\": 73,",
                                "      \"promptTokens\": 782,",
                                "      \"totalTokens\": 855",
                                "    }",
                                "  }",
                                "}",
                                "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m5:chain:LLMChain\u001b[22m\u001b[39m] [4.94s] Exiting Chain run with output: {",
                                "  \"text\": \"{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"The weather in Pomfret, CT is currently clear with a temperature of 55 degrees Fahrenheit. There is a 4% chance of precipitation, humidity is at 100%, and the wind speed is 2 mph. This information is as of Wednesday 6:00 AM.\\\"\\n}\"",
                                "}",
                                "Got output The weather in Pomfret, CT is currently clear with a temperature of 55 degrees Fahrenheit. There is a 4% chance of precipitation, humidity is at 100%, and the wind speed is 2 mph. This information is as of Wednesday 6:00 AM.",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { OpenAI } from \"langchain/llms/openai\";\nimport { HNSWLib } from \"langchain/vectorstores/hnswlib\";\nimport { OpenAIEmbeddings } from \"langchain/embeddings/openai\";\nimport { RecursiveCharacterTextSplitter } from \"langchain/text_splitter\";\nimport * as fs from \"fs\";\nimport {\n  VectorStoreToolkit,\n  createVectorStoreAgent,\n  VectorStoreInfo,\n} from \"langchain/agents\";\n\nconst model = new OpenAI({ temperature: 0 });\n/* Load in the file we want to do question answering over */\nconst text = fs.readFileSync(\"data/state_of_the_union.txt\", \"utf8\");\n/* Split the text into chunks using character, not token, size */\nconst textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000 });\nconst docs = await textSplitter.createDocuments([text]);\n/* Create the vectorstore */\nconst vectorStore = await HNSWLib.fromDocuments(docs, new OpenAIEmbeddings());\n\n/* Create the agent */\nconst vectorStoreInfo: VectorStoreInfo = {\n  name: \"state_of_union_address\",\n  description: \"the most recent state of the Union address\",\n  vectorStore,\n};\n\nconst toolkit = new VectorStoreToolkit(vectorStoreInfo, model);\nconst agent = createVectorStoreAgent(model, toolkit);\n\nconst input =\n  \"What did biden say about Ketanji Brown Jackson is the state of the union address?\";\nconsole.log(`Executing: ${input}`);\n\nconst result = await agent.call({ input });\nconsole.log(`Got output ${result.output}`);\nconsole.log(\n  `Got intermediate steps ${JSON.stringify(result.intermediateSteps, null, 2)}`\n);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "Executing: What did biden say about Ketanji Brown Jackson is the state of the union address?",
                                "Got output Biden said that Jackson is one of the nation's top legal minds and will continue Justice Breyer's legacy of excellence. She is a former top litigator in private practice, a former federal public defender, and from a family of public school educators and police officers. She has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.",
                                "Got intermediate steps [",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"state_of_union_address\",",
                                "      \"toolInput\": \"What did Biden say about Ketanji Brown Jackson?\",",
                                "      \"log\": \" I need to find out what Biden said about Ketanji Brown Jackson in the state of the union address.\\nAction: state_of_union_address\\nAction Input: What did Biden say about Ketanji Brown Jackson?\"",
                                "    },",
                                "    \"observation\": \" Biden said that Jackson is one of the nation's top legal minds and will continue Justice Breyer's legacy of excellence. She is a former top litigator in private practice, a former federal public defender, and from a family of public school educators and police officers. She has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\"",
                                "  }",
                                "]",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import { OpenAI } from \"langchain/llms/openai\";\nimport { SqlDatabase } from \"langchain/sql_db\";\nimport { createSqlAgent, SqlToolkit } from \"langchain/agents/toolkits/sql\";\nimport { DataSource } from \"typeorm\";\n\n/** This example uses Chinook database, which is a sample database available for SQL Server, Oracle, MySQL, etc.\n * To set it up follow the instructions on https://database.guide/2-sample-databases-sqlite/, placing the .db file\n * in the examples folder.\n */\nconst datasource = new DataSource({\n  type: \"sqlite\",\n  database: \"data/Chinook.db\",\n});\nconst db = await SqlDatabase.fromDataSourceParams({\n  appDataSource: datasource,\n});\nconst model = new OpenAI({ temperature: 0 });\nconst toolkit = new SqlToolkit(db, model);\nconst executor = createSqlAgent(model, toolkit);\n\nconst input = `List the total sales per country. Which country's customers spent the most?`;\n\nconsole.log(`Executing with input \"${input}\"...`);\n\nconst result = await executor.call({ input });\n\nconsole.log(`Got output ${result.output}`);\n\nconsole.log(\n  `Got intermediate steps ${JSON.stringify(\n    result.intermediateSteps,\n    null,\n    2\n  )}`\n);\n\nawait datasource.destroy();\n"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "Executing with input \"List the total sales per country. Which country's customers spent the most?\"...",
                                "Got intermediate steps [",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"list-tables-sql\",",
                                "      \"toolInput\": \"\",",
                                "      \"log\": \"Action: list-tables-sql\\nAction Input: \\\"\\\"\"",
                                "    },",
                                "    \"observation\": \"Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"info-sql\",",
                                "      \"toolInput\": \"Invoice, Customer\",",
                                "      \"log\": \" I should look at the schema of the relevant tables to see what columns I need.\\nAction: info-sql\\nAction Input: \\\"Invoice, Customer\\\"\"",
                                "    },",
                                "    \"observation\": \"CREATE TABLE Customer (\\nCustomerId INTEGER NOT NULL, FirstName NVARCHAR(40) NOT NULL, LastName NVARCHAR(20) NOT NULL, Company NVARCHAR(80) , Address NVARCHAR(70) , City NVARCHAR(40) , State NVARCHAR(40) , Country NVARCHAR(40) , PostalCode NVARCHAR(10) , Phone NVARCHAR(24) , Fax NVARCHAR(24) , Email NVARCHAR(60) NOT NULL, SupportRepId INTEGER ) \\nSELECT * FROM \\\"Customer\\\" LIMIT 3;\\n CustomerId FirstName LastName Company Address City State Country PostalCode Phone Fax Email SupportRepId\\n 1 Luís Gonçalves Embraer - Empresa Brasileira de Aeronáutica S.A. Av. Brigadeiro Faria Lima, 2170 São José dos Campos SP Brazil 12227-000 +55 (12) 3923-5555 +55 (12) 3923-5566 luisg@embraer.com.br 3\\n 2 Leonie Köhler null Theodor-Heuss-Straße 34 Stuttgart null Germany 70174 +49 0711 2842222 null leonekohler@surfeu.de 5\\n 3 François Tremblay null 1498 rue Bélanger Montréal QC Canada H2G 1A7 +1 (514) 721-4711 null ftremblay@gmail.com 3\\nCREATE TABLE Invoice (\\nInvoiceId INTEGER NOT NULL, CustomerId INTEGER NOT NULL, InvoiceDate DATETIME NOT NULL, BillingAddress NVARCHAR(70) , BillingCity NVARCHAR(40) , BillingState NVARCHAR(40) , BillingCountry NVARCHAR(40) , BillingPostalCode NVARCHAR(10) , Total NUMERIC(10,2) NOT NULL) \\nSELECT * FROM \\\"Invoice\\\" LIMIT 3;\\n InvoiceId CustomerId InvoiceDate BillingAddress BillingCity BillingState BillingCountry BillingPostalCode Total\\n 1 2 2009-01-01 00:00:00 Theodor-Heuss-Straße 34 Stuttgart null Germany 70174 1.98\\n 2 4 2009-01-02 00:00:00 Ullevålsveien 14 Oslo null Norway 0171 3.96\\n 3 8 2009-01-03 00:00:00 Grétrystraat 63 Brussels null Belgium 1000 5.94\\n\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"query-sql\",",
                                "      \"toolInput\": \"SELECT Customer.Country, SUM(Invoice.Total) AS TotalSales FROM Invoice INNER JOIN Customer ON Invoice.CustomerId = Customer.CustomerId GROUP BY Customer.Country ORDER BY TotalSales DESC LIMIT 10;\",",
                                "      \"log\": \" I need to join the Invoice and Customer tables to get the total sales per country.\\nAction: query-sql\\nAction Input: SELECT Customer.Country, SUM(Invoice.Total) AS TotalSales FROM Invoice INNER JOIN Customer ON Invoice.CustomerId = Customer.CustomerId GROUP BY Customer.Country ORDER BY TotalSales DESC LIMIT 10;\"",
                                "    },",
                                "    \"observation\": \"[{\\\"Country\\\":\\\"USA\\\",\\\"TotalSales\\\":523.0600000000003},{\\\"Country\\\":\\\"Canada\\\",\\\"TotalSales\\\":303.9599999999999},{\\\"Country\\\":\\\"France\\\",\\\"TotalSales\\\":195.09999999999994},{\\\"Country\\\":\\\"Brazil\\\",\\\"TotalSales\\\":190.09999999999997},{\\\"Country\\\":\\\"Germany\\\",\\\"TotalSales\\\":156.48},{\\\"Country\\\":\\\"United Kingdom\\\",\\\"TotalSales\\\":112.85999999999999},{\\\"Country\\\":\\\"Czech Republic\\\",\\\"TotalSales\\\":90.24000000000001},{\\\"Country\\\":\\\"Portugal\\\",\\\"TotalSales\\\":77.23999999999998},{\\\"Country\\\":\\\"India\\\",\\\"TotalSales\\\":75.25999999999999},{\\\"Country\\\":\\\"Chile\\\",\\\"TotalSales\\\":46.62}]\"",
                                "  }",
                                "]",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import * as fs from \"fs\";\nimport * as yaml from \"js-yaml\";\nimport { OpenAI } from \"langchain/llms/openai\";\nimport { JsonSpec, JsonObject } from \"langchain/tools\";\nimport { JsonToolkit, createJsonAgent } from \"langchain/agents\";\n\nlet data: JsonObject;\ntry {\n  const yamlFile = fs.readFileSync(\"data/openai_openapi.yaml\", \"utf8\");\n  data = yaml.load(yamlFile) as JsonObject;\n  if (!data) {\n    throw new Error(\"Failed to load OpenAPI spec\");\n  }\n} catch (e) {\n  console.error(e);\n}\n\nconst toolkit = new JsonToolkit(new JsonSpec(data));\nconst model = new OpenAI({ temperature: 0 });\nconst executor = createJsonAgent(model, toolkit);\n\nconst input = `What are the required parameters in the request body to the /completions endpoint?`;\n\nconsole.log(`Executing with input \"${input}\"...`);\n\nconst result = await executor.call({ input });\n\nconsole.log(`Got output ${result.output}`);\n\nconsole.log(\n  `Got intermediate steps ${JSON.stringify(\n    result.intermediateSteps,\n    null,\n    2\n  )}`\n);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "Executing with input \"What are the required parameters in the request body to the /completions endpoint?\"...",
                                "Got intermediate steps [",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"json_list_keys\",",
                                "      \"toolInput\": \"\",",
                                "      \"log\": \"Action: json_list_keys\\nAction Input: \\\"\\\"\"",
                                "    },",
                                "    \"observation\": \"openapi, info, servers, tags, paths, components, x-oaiMeta\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"json_list_keys\",",
                                "      \"toolInput\": \"/paths\",",
                                "      \"log\": \" I should look at the 'paths' key to see what parameters are required for the /completions endpoint.\\nAction: json_list_keys\\nAction Input: \\\"/paths\\\"\"",
                                "    },",
                                "    \"observation\": \"~1engines, ~1engines~1{engine_id}, ~1completions, ~1edits, ~1images~1generations, ~1images~1edits, ~1images~1variations, ~1embeddings, ~1engines~1{engine_id}~1search, ~1files, ~1files~1{file_id}, ~1files~1{file_id}~1content, ~1answers, ~1classifications, ~1fine-tunes, ~1fine-tunes~1{fine_tune_id}, ~1fine-tunes~1{fine_tune_id}~1cancel, ~1fine-tunes~1{fine_tune_id}~1events, ~1models, ~1models~1{model}, ~1moderations\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"json_list_keys\",",
                                "      \"toolInput\": \"/paths/~1completions\",",
                                "      \"log\": \" I should look at the '~1completions' key to see what parameters are required for the /completions endpoint.\\nAction: json_list_keys\\nAction Input: \\\"/paths/~1completions\\\"\"",
                                "    },",
                                "    \"observation\": \"post\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"json_list_keys\",",
                                "      \"toolInput\": \"/paths/~1completions/post\",",
                                "      \"log\": \" I should look at the 'post' key to see what parameters are required for the /completions endpoint.\\nAction: json_list_keys\\nAction Input: \\\"/paths/~1completions/post\\\"\"",
                                "    },",
                                "    \"observation\": \"operationId, tags, summary, requestBody, responses, x-oaiMeta\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"json_list_keys\",",
                                "      \"toolInput\": \"/paths/~1completions/post/requestBody\",",
                                "      \"log\": \" I should look at the 'requestBody' key to see what parameters are required for the /completions endpoint.\\nAction: json_list_keys\\nAction Input: \\\"/paths/~1completions/post/requestBody\\\"\"",
                                "    },",
                                "    \"observation\": \"required, content\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"json_get_value\",",
                                "      \"toolInput\": \"/paths/~1completions/post/requestBody/required\",",
                                "      \"log\": \" I should look at the 'required' key to see what parameters are required for the /completions endpoint.\\nAction: json_get_value\\nAction Input: \\\"/paths/~1completions/post/requestBody/required\\\"\"",
                                "    },",
                                "    \"observation\": \"true\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"json_list_keys\",",
                                "      \"toolInput\": \"/paths/~1completions/post/requestBody/content\",",
                                "      \"log\": \" I should look at the 'content' key to see what parameters are required for the /completions endpoint.\\nAction: json_list_keys\\nAction Input: \\\"/paths/~1completions/post/requestBody/content\\\"\"",
                                "    },",
                                "    \"observation\": \"application~1json\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"json_list_keys\",",
                                "      \"toolInput\": \"/paths/~1completions/post/requestBody/content/application~1json\",",
                                "      \"log\": \" I should look at the 'application~1json' key to see what parameters are required for the /completions endpoint.\\nAction: json_list_keys\\nAction Input: \\\"/paths/~1completions/post/requestBody/content/application~1json\\\"\"",
                                "    },",
                                "    \"observation\": \"schema\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"json_list_keys\",",
                                "      \"toolInput\": \"/paths/~1completions/post/requestBody/content/application~1json/schema\",",
                                "      \"log\": \" I should look at the 'schema' key to see what parameters are required for the /completions endpoint.\\nAction: json_list_keys\\nAction Input: \\\"/paths/~1completions/post/requestBody/content/application~1json/schema\\\"\"",
                                "    },",
                                "    \"observation\": \"$ref\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"json_get_value\",",
                                "      \"toolInput\": \"/paths/~1completions/post/requestBody/content/application~1json/schema/$ref\",",
                                "      \"log\": \" I should look at the '$ref' key to see what parameters are required for the /completions endpoint.\\nAction: json_get_value\\nAction Input: \\\"/paths/~1completions/post/requestBody/content/application~1json/schema/$ref\\\"\"",
                                "    },",
                                "    \"observation\": \"#/components/schemas/CreateCompletionRequest\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"json_list_keys\",",
                                "      \"toolInput\": \"/components/schemas/CreateCompletionRequest\",",
                                "      \"log\": \" I should look at the 'CreateCompletionRequest' schema to see what parameters are required for the /completions endpoint.\\nAction: json_list_keys\\nAction Input: \\\"/components/schemas/CreateCompletionRequest\\\"\"",
                                "    },",
                                "    \"observation\": \"type, properties, required\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"json_get_value\",",
                                "      \"toolInput\": \"/components/schemas/CreateCompletionRequest/required\",",
                                "      \"log\": \" I should look at the 'required' key to see what parameters are required for the /completions endpoint.\\nAction: json_get_value\\nAction Input: \\\"/components/schemas/CreateCompletionRequest/required\\\"\"",
                                "    },",
                                "    \"observation\": \"[\\\"model\\\"]\"",
                                "  }",
                                "]",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "typescript",
            "source": [
                "import * as fs from \"fs\";\nimport * as yaml from \"js-yaml\";\nimport { OpenAI } from \"langchain/llms/openai\";\nimport { JsonSpec, JsonObject } from \"langchain/tools\";\nimport { createOpenApiAgent, OpenApiToolkit } from \"langchain/agents\";\n\nlet data: JsonObject;\ntry {\n  const yamlFile = fs.readFileSync(\"data/openai_openapi.yaml\", \"utf8\");\n  data = yaml.load(yamlFile) as JsonObject;\n  if (!data) {\n    throw new Error(\"Failed to load OpenAPI spec\");\n  }\n} catch (e) {\n  console.error(e);\n}\n\nconst headers = {\n  \"Content-Type\": \"application/json\",\n  Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,\n};\nconst model = new OpenAI({ temperature: 0 });\nconst toolkit = new OpenApiToolkit(new JsonSpec(data), model, headers);\nconst executor = createOpenApiAgent(model, toolkit);\n\nconst input = `Make a POST request to openai /completions. The prompt should be 'tell me a joke.'`;\nconsole.log(`Executing with input \"${input}\"...`);\n\nconst result = await executor.call({ input });\nconsole.log(`Got output ${result.output}`);\n\nconsole.log(\n  `Got intermediate steps ${JSON.stringify(\n    result.intermediateSteps,\n    null,\n    2\n  )}`\n);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "Executing with input \"Make a POST request to openai /completions. The prompt should be 'tell me a joke.'\"...",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stderr",
                            "value": [
                                "(node:1802) Warning: Setting the NODE_TLS_REJECT_UNAUTHORIZED environment variable to '0' makes TLS connections and HTTPS requests insecure by disabling certificate verification.",
                                "(Use `node --trace-warnings ...` to show where the warning was created)",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "Got output \".\\\"\\n\\n\\\"We're not the ones making all the jokes,\\\" Tam Jae\"",
                                "Got intermediate steps [",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"json_explorer\",",
                                "      \"toolInput\": \"What is the base url for the API?\",",
                                "      \"log\": \"Action: json_explorer\\nAction Input: What is the base url for the API?\"",
                                "    },",
                                "    \"observation\": \"The base url for the API is https://api.openai.com/v1.\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"json_explorer\",",
                                "      \"toolInput\": \"What is the path for the /completions endpoint?\",",
                                "      \"log\": \" I should find the path for the /completions endpoint.\\nAction: json_explorer\\nAction Input: What is the path for the /completions endpoint?\"",
                                "    },",
                                "    \"observation\": \"The path for the /completions endpoint is /completions.\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"json_explorer\",",
                                "      \"toolInput\": \"What are the required parameters for a POST request to the /completions endpoint?\",",
                                "      \"log\": \" I should find the required parameters for the POST request.\\nAction: json_explorer\\nAction Input: What are the required parameters for a POST request to the /completions endpoint?\"",
                                "    },",
                                "    \"observation\": \"The required parameters for a POST request to the /completions endpoint are \\\"model\\\".\"",
                                "  },",
                                "  {",
                                "    \"action\": {",
                                "      \"tool\": \"requests_post\",",
                                "      \"toolInput\": \"{ \\\"url\\\": \\\"https://api.openai.com/v1/completions\\\", \\\"data\\\": { \\\"model\\\": \\\"davinci\\\", \\\"prompt\\\": \\\"tell me a joke\\\" } }\",",
                                "      \"log\": \" I should make the POST request.\\nAction: requests_post\\nAction Input: { \\\"url\\\": \\\"https://api.openai.com/v1/completions\\\", \\\"data\\\": { \\\"model\\\": \\\"davinci\\\", \\\"prompt\\\": \\\"tell me a joke\\\" } }\"",
                                "    },",
                                "    \"observation\": \"{\\n  \\\"id\\\": \\\"cmpl-86VVndlNLaqXLCN38CleZOEqvplMW\\\",\\n  \\\"object\\\": \\\"text_completion\\\",\\n  \\\"created\\\": 1696561791,\\n  \\\"model\\\": \\\"davinci\\\",\\n  \\\"choices\\\": [\\n    {\\n      \\\"text\\\": \\\".\\\\\\\"\\\\n\\\\n\\\\\\\"We're not the ones making all the jokes,\\\\\\\" Tam Jae\\\",\\n      \\\"index\\\": 0,\\n      \\\"logprobs\\\": null,\\n      \\\"finish_reason\\\": \\\"length\\\"\\n    }\\n  ],\\n  \\\"usage\\\": {\\n    \\\"prompt_tokens\\\": 4,\\n    \\\"completion_tokens\\\": 16,\\n    \\\"total_tokens\\\": 20\\n  }\\n}\\n\"",
                                "  }",
                                "]",
                                ""
                            ]
                        }
                    ]
                }
            ]
        }
    ]
}